{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.models import *\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import signal\n",
    "import stldecompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>QQQ.Open</th>\n",
       "      <th>QQQ.High</th>\n",
       "      <th>QQQ.Low</th>\n",
       "      <th>QQQ.Close</th>\n",
       "      <th>QQQ.Volume</th>\n",
       "      <th>QQQ.Adjusted</th>\n",
       "      <th>TSLA.Open</th>\n",
       "      <th>TSLA.High</th>\n",
       "      <th>TSLA.Low</th>\n",
       "      <th>...</th>\n",
       "      <th>TLRY.Low</th>\n",
       "      <th>TLRY.Close</th>\n",
       "      <th>TLRY.Volume</th>\n",
       "      <th>TLRY.Adjusted</th>\n",
       "      <th>MU.Open</th>\n",
       "      <th>MU.High</th>\n",
       "      <th>MU.Low</th>\n",
       "      <th>MU.Close</th>\n",
       "      <th>MU.Volume</th>\n",
       "      <th>MU.Adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>182.250000</td>\n",
       "      <td>184.850006</td>\n",
       "      <td>182.210007</td>\n",
       "      <td>183.149994</td>\n",
       "      <td>41385300</td>\n",
       "      <td>183.149994</td>\n",
       "      <td>210.250000</td>\n",
       "      <td>216.940002</td>\n",
       "      <td>209.009995</td>\n",
       "      <td>...</td>\n",
       "      <td>41.029999</td>\n",
       "      <td>43.139999</td>\n",
       "      <td>7322600</td>\n",
       "      <td>43.139999</td>\n",
       "      <td>34.599998</td>\n",
       "      <td>35.540001</td>\n",
       "      <td>34.520000</td>\n",
       "      <td>34.939999</td>\n",
       "      <td>21728000</td>\n",
       "      <td>34.939999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>185.059998</td>\n",
       "      <td>185.399994</td>\n",
       "      <td>182.779999</td>\n",
       "      <td>183.399994</td>\n",
       "      <td>41260300</td>\n",
       "      <td>183.399994</td>\n",
       "      <td>219.139999</td>\n",
       "      <td>220.899994</td>\n",
       "      <td>213.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.139999</td>\n",
       "      <td>40.490002</td>\n",
       "      <td>2898900</td>\n",
       "      <td>40.490002</td>\n",
       "      <td>35.799999</td>\n",
       "      <td>35.990002</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>34.840000</td>\n",
       "      <td>19208600</td>\n",
       "      <td>34.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>182.899994</td>\n",
       "      <td>183.279999</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>182.339996</td>\n",
       "      <td>27758100</td>\n",
       "      <td>182.339996</td>\n",
       "      <td>222.949997</td>\n",
       "      <td>223.380005</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>39.430000</td>\n",
       "      <td>41.820000</td>\n",
       "      <td>1702500</td>\n",
       "      <td>41.820000</td>\n",
       "      <td>34.009998</td>\n",
       "      <td>34.099998</td>\n",
       "      <td>32.730000</td>\n",
       "      <td>32.959999</td>\n",
       "      <td>28746500</td>\n",
       "      <td>32.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>183.100006</td>\n",
       "      <td>183.869995</td>\n",
       "      <td>182.740005</td>\n",
       "      <td>183.419998</td>\n",
       "      <td>23715800</td>\n",
       "      <td>183.419998</td>\n",
       "      <td>210.380005</td>\n",
       "      <td>214.899994</td>\n",
       "      <td>207.509995</td>\n",
       "      <td>...</td>\n",
       "      <td>40.400002</td>\n",
       "      <td>40.700001</td>\n",
       "      <td>1167200</td>\n",
       "      <td>40.700001</td>\n",
       "      <td>33.080002</td>\n",
       "      <td>33.639999</td>\n",
       "      <td>33.009998</td>\n",
       "      <td>33.380001</td>\n",
       "      <td>16586700</td>\n",
       "      <td>33.380001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>182.479996</td>\n",
       "      <td>183.110001</td>\n",
       "      <td>181.940002</td>\n",
       "      <td>182.639999</td>\n",
       "      <td>22834000</td>\n",
       "      <td>182.639999</td>\n",
       "      <td>211.250000</td>\n",
       "      <td>216.649994</td>\n",
       "      <td>210.399994</td>\n",
       "      <td>...</td>\n",
       "      <td>38.700001</td>\n",
       "      <td>39.009998</td>\n",
       "      <td>1368200</td>\n",
       "      <td>39.009998</td>\n",
       "      <td>32.450001</td>\n",
       "      <td>32.840000</td>\n",
       "      <td>32.240002</td>\n",
       "      <td>32.660000</td>\n",
       "      <td>19700800</td>\n",
       "      <td>32.660000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Index    QQQ.Open    QQQ.High     QQQ.Low   QQQ.Close  QQQ.Volume  \\\n",
       "863  2019-06-10  182.250000  184.850006  182.210007  183.149994    41385300   \n",
       "864  2019-06-11  185.059998  185.399994  182.779999  183.399994    41260300   \n",
       "865  2019-06-12  182.899994  183.279999  182.000000  182.339996    27758100   \n",
       "866  2019-06-13  183.100006  183.869995  182.740005  183.419998    23715800   \n",
       "867  2019-06-14  182.479996  183.110001  181.940002  182.639999    22834000   \n",
       "\n",
       "     QQQ.Adjusted   TSLA.Open   TSLA.High    TSLA.Low     ...        TLRY.Low  \\\n",
       "863    183.149994  210.250000  216.940002  209.009995     ...       41.029999   \n",
       "864    183.399994  219.139999  220.899994  213.500000     ...       40.139999   \n",
       "865    182.339996  222.949997  223.380005  209.000000     ...       39.430000   \n",
       "866    183.419998  210.380005  214.899994  207.509995     ...       40.400002   \n",
       "867    182.639999  211.250000  216.649994  210.399994     ...       38.700001   \n",
       "\n",
       "     TLRY.Close  TLRY.Volume  TLRY.Adjusted    MU.Open    MU.High     MU.Low  \\\n",
       "863   43.139999      7322600      43.139999  34.599998  35.540001  34.520000   \n",
       "864   40.490002      2898900      40.490002  35.799999  35.990002  34.750000   \n",
       "865   41.820000      1702500      41.820000  34.009998  34.099998  32.730000   \n",
       "866   40.700001      1167200      40.700001  33.080002  33.639999  33.009998   \n",
       "867   39.009998      1368200      39.009998  32.450001  32.840000  32.240002   \n",
       "\n",
       "      MU.Close  MU.Volume  MU.Adjusted  \n",
       "863  34.939999   21728000    34.939999  \n",
       "864  34.840000   19208600    34.840000  \n",
       "865  32.959999   28746500    32.959999  \n",
       "866  33.380001   16586700    33.380001  \n",
       "867  32.660000   19700800    32.660000  \n",
       "\n",
       "[5 rows x 325 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_orig = pd.read_csv('../data/files/multiple_concatenated_tickers.csv')\n",
    "data_orig.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>volatilityQQQ</th>\n",
       "      <th>volatilityTSLA</th>\n",
       "      <th>volatilityMSFT</th>\n",
       "      <th>volatilityINTC</th>\n",
       "      <th>volatilityAAPL</th>\n",
       "      <th>volatilityNFLX</th>\n",
       "      <th>volatilityAMZN</th>\n",
       "      <th>volatilityFB</th>\n",
       "      <th>volatilityGOOG</th>\n",
       "      <th>...</th>\n",
       "      <th>volatilityXLY</th>\n",
       "      <th>volatilityXLP</th>\n",
       "      <th>volatilityXLV</th>\n",
       "      <th>volatilityXLF</th>\n",
       "      <th>volatilityXLK</th>\n",
       "      <th>volatilityXTL</th>\n",
       "      <th>volatilityXLU</th>\n",
       "      <th>volatilityXLRE</th>\n",
       "      <th>volatilityTLRY</th>\n",
       "      <th>volatilityMU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>0.262443</td>\n",
       "      <td>0.574566</td>\n",
       "      <td>0.333510</td>\n",
       "      <td>0.253769</td>\n",
       "      <td>0.281142</td>\n",
       "      <td>0.381002</td>\n",
       "      <td>0.409732</td>\n",
       "      <td>0.517354</td>\n",
       "      <td>0.406953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202950</td>\n",
       "      <td>0.150711</td>\n",
       "      <td>0.130785</td>\n",
       "      <td>0.183441</td>\n",
       "      <td>0.267121</td>\n",
       "      <td>0.202553</td>\n",
       "      <td>0.168077</td>\n",
       "      <td>0.155938</td>\n",
       "      <td>1.063379</td>\n",
       "      <td>0.412362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>0.253383</td>\n",
       "      <td>0.573597</td>\n",
       "      <td>0.326130</td>\n",
       "      <td>0.252188</td>\n",
       "      <td>0.269323</td>\n",
       "      <td>0.369345</td>\n",
       "      <td>0.404458</td>\n",
       "      <td>0.531756</td>\n",
       "      <td>0.402374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187672</td>\n",
       "      <td>0.134942</td>\n",
       "      <td>0.109451</td>\n",
       "      <td>0.181765</td>\n",
       "      <td>0.260561</td>\n",
       "      <td>0.200543</td>\n",
       "      <td>0.150839</td>\n",
       "      <td>0.130113</td>\n",
       "      <td>1.092160</td>\n",
       "      <td>0.414424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>0.259465</td>\n",
       "      <td>0.628408</td>\n",
       "      <td>0.331261</td>\n",
       "      <td>0.266931</td>\n",
       "      <td>0.278214</td>\n",
       "      <td>0.377129</td>\n",
       "      <td>0.405765</td>\n",
       "      <td>0.535325</td>\n",
       "      <td>0.401467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189846</td>\n",
       "      <td>0.136326</td>\n",
       "      <td>0.109338</td>\n",
       "      <td>0.192895</td>\n",
       "      <td>0.268465</td>\n",
       "      <td>0.203165</td>\n",
       "      <td>0.158621</td>\n",
       "      <td>0.129671</td>\n",
       "      <td>1.072741</td>\n",
       "      <td>0.527995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>0.231038</td>\n",
       "      <td>0.605956</td>\n",
       "      <td>0.304988</td>\n",
       "      <td>0.239902</td>\n",
       "      <td>0.232847</td>\n",
       "      <td>0.353386</td>\n",
       "      <td>0.375983</td>\n",
       "      <td>0.518845</td>\n",
       "      <td>0.404909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156865</td>\n",
       "      <td>0.076984</td>\n",
       "      <td>0.091795</td>\n",
       "      <td>0.159182</td>\n",
       "      <td>0.234898</td>\n",
       "      <td>0.125690</td>\n",
       "      <td>0.158864</td>\n",
       "      <td>0.127678</td>\n",
       "      <td>1.070979</td>\n",
       "      <td>0.517080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>0.172617</td>\n",
       "      <td>0.533444</td>\n",
       "      <td>0.202580</td>\n",
       "      <td>0.234044</td>\n",
       "      <td>0.224527</td>\n",
       "      <td>0.340522</td>\n",
       "      <td>0.205248</td>\n",
       "      <td>0.225017</td>\n",
       "      <td>0.167734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131051</td>\n",
       "      <td>0.074474</td>\n",
       "      <td>0.099594</td>\n",
       "      <td>0.159437</td>\n",
       "      <td>0.207356</td>\n",
       "      <td>0.149072</td>\n",
       "      <td>0.159537</td>\n",
       "      <td>0.127758</td>\n",
       "      <td>0.946152</td>\n",
       "      <td>0.533473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Index  volatilityQQQ  volatilityTSLA  volatilityMSFT  \\\n",
       "863  2019-06-10       0.262443        0.574566        0.333510   \n",
       "864  2019-06-11       0.253383        0.573597        0.326130   \n",
       "865  2019-06-12       0.259465        0.628408        0.331261   \n",
       "866  2019-06-13       0.231038        0.605956        0.304988   \n",
       "867  2019-06-14       0.172617        0.533444        0.202580   \n",
       "\n",
       "     volatilityINTC  volatilityAAPL  volatilityNFLX  volatilityAMZN  \\\n",
       "863        0.253769        0.281142        0.381002        0.409732   \n",
       "864        0.252188        0.269323        0.369345        0.404458   \n",
       "865        0.266931        0.278214        0.377129        0.405765   \n",
       "866        0.239902        0.232847        0.353386        0.375983   \n",
       "867        0.234044        0.224527        0.340522        0.205248   \n",
       "\n",
       "     volatilityFB  volatilityGOOG      ...       volatilityXLY  volatilityXLP  \\\n",
       "863      0.517354        0.406953      ...            0.202950       0.150711   \n",
       "864      0.531756        0.402374      ...            0.187672       0.134942   \n",
       "865      0.535325        0.401467      ...            0.189846       0.136326   \n",
       "866      0.518845        0.404909      ...            0.156865       0.076984   \n",
       "867      0.225017        0.167734      ...            0.131051       0.074474   \n",
       "\n",
       "     volatilityXLV  volatilityXLF  volatilityXLK  volatilityXTL  \\\n",
       "863       0.130785       0.183441       0.267121       0.202553   \n",
       "864       0.109451       0.181765       0.260561       0.200543   \n",
       "865       0.109338       0.192895       0.268465       0.203165   \n",
       "866       0.091795       0.159182       0.234898       0.125690   \n",
       "867       0.099594       0.159437       0.207356       0.149072   \n",
       "\n",
       "     volatilityXLU  volatilityXLRE  volatilityTLRY  volatilityMU  \n",
       "863       0.168077        0.155938        1.063379      0.412362  \n",
       "864       0.150839        0.130113        1.092160      0.414424  \n",
       "865       0.158621        0.129671        1.072741      0.527995  \n",
       "866       0.158864        0.127678        1.070979      0.517080  \n",
       "867       0.159537        0.127758        0.946152      0.533473  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_data_orig = pd.read_csv('../data/files/multiple_concatenated_tickers_volatility.csv')\n",
    "# vol_data20_orig = pd.read_csv('../data/files/multiple_concatenated_tickers_volatility20.csv')\n",
    "#vol_data50_orig = pd.read_csv('../data/files/multiple_concatenated_tickers_volatility50.csv')\n",
    "#vol_data100_orig = pd.read_csv('../data/files/multiple_concatenated_tickers_volatility100.csv')\n",
    "vol_data_orig.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_orig = data_orig\\\n",
    "  .merge(vol_data_orig, how=\"inner\", left_on=data_orig.Index, right_on=vol_data_orig.Index).fillna(method=\"ffill\")\\\n",
    "  .drop([\"key_0\", \"Index_y\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in list(data_orig.columns) if i == 'Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from keras.preprocessing import *\n",
    "from nltk.stem import SnowballStemmer\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "\n",
    "data = []\n",
    "for i in os.listdir(\"../briefings/\"):\n",
    "    #print(i)\n",
    "    f = open(\"../briefings/\"+str(i), \"rb\")\n",
    "    d = pickle.loads(f.read())\n",
    "    data.append(d)\n",
    "\n",
    "def categories(n, p):\n",
    "    n = float(n)\n",
    "    p = float(p)\n",
    "    if n >= p:\n",
    "        return np.array([0, 0, 1])\n",
    "    if n <= -p:\n",
    "        return np.array([1, 0, 0])\n",
    "    else:\n",
    "        return np.array([0, 1, 0])\n",
    "    \n",
    "#Headlines\n",
    "headlines = []\n",
    "text_bodies = []\n",
    "all_text = []\n",
    "dates = []\n",
    "targets = []\n",
    "snow = SnowballStemmer('english')\n",
    "for i,v in enumerate(data):\n",
    "    for k in v:\n",
    "        if k[\"date\"] == -1:\n",
    "            continue\n",
    "        else:\n",
    "            ticker_data = k[\"tickerinfo\"]\n",
    "            if not ticker_data:\n",
    "                continue\n",
    "            if len(ticker_data[1]) == 4:\n",
    "                w = parse(k[\"date\"])\n",
    "                targets.append([w, categories(ticker_data[1][3].replace(\"(\",\"\").replace(\")\",\"\").replace(\"%\",\"\"), 1.0)]) # for regression\n",
    "                headlines.append(''.join([snow.stem(w) for w in str(k[\"headline\"])]))\n",
    "                text_bodies.append(''.join([snow.stem(w) for w in str(k[\"text\"])]))\n",
    "                all_text.append(''.join([snow.stem(w) for w in str(k[\"headline\"])]+[snow.stem(w) for w in str(k[\"text\"])]))\n",
    "                dates.append(w.date().isoformat())\n",
    "#                 all_text.append(''.join([snow.stem(w) for w in str(k[\"text\"])]))\n",
    "                dates.append(w.date().isoformat())\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=500, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0, 1, 0]\n",
       "1        [0, 1, 0]\n",
       "2        [0, 1, 0]\n",
       "3        [0, 1, 0]\n",
       "4        [0, 1, 0]\n",
       "5        [0, 1, 0]\n",
       "6        [0, 1, 0]\n",
       "7        [0, 1, 0]\n",
       "8        [0, 1, 0]\n",
       "9        [0, 1, 0]\n",
       "10       [0, 1, 0]\n",
       "11       [0, 1, 0]\n",
       "12       [0, 1, 0]\n",
       "13       [0, 1, 0]\n",
       "14       [1, 0, 0]\n",
       "15       [0, 1, 0]\n",
       "16       [0, 1, 0]\n",
       "17       [0, 1, 0]\n",
       "18       [0, 1, 0]\n",
       "19       [0, 1, 0]\n",
       "20       [0, 1, 0]\n",
       "21       [0, 1, 0]\n",
       "22       [0, 1, 0]\n",
       "23       [0, 1, 0]\n",
       "24       [0, 1, 0]\n",
       "25       [0, 1, 0]\n",
       "26       [0, 1, 0]\n",
       "27       [0, 1, 0]\n",
       "28       [0, 1, 0]\n",
       "29       [0, 1, 0]\n",
       "           ...    \n",
       "12103    [0, 1, 0]\n",
       "12104    [0, 1, 0]\n",
       "12105    [0, 1, 0]\n",
       "12106    [0, 1, 0]\n",
       "12107    [0, 1, 0]\n",
       "12108    [0, 1, 0]\n",
       "12109    [0, 1, 0]\n",
       "12110    [0, 1, 0]\n",
       "12111    [0, 1, 0]\n",
       "12112    [0, 1, 0]\n",
       "12113    [0, 1, 0]\n",
       "12114    [0, 1, 0]\n",
       "12115    [0, 1, 0]\n",
       "12116    [0, 1, 0]\n",
       "12117    [0, 1, 0]\n",
       "12118    [0, 1, 0]\n",
       "12119    [0, 1, 0]\n",
       "12120    [0, 1, 0]\n",
       "12121    [0, 1, 0]\n",
       "12122    [0, 1, 0]\n",
       "12123    [0, 1, 0]\n",
       "12124    [0, 1, 0]\n",
       "12125    [0, 1, 0]\n",
       "12126    [0, 1, 0]\n",
       "12127    [0, 1, 0]\n",
       "12128    [0, 1, 0]\n",
       "12129    [0, 1, 0]\n",
       "12130    [0, 1, 0]\n",
       "12131    [0, 1, 0]\n",
       "12132    [0, 1, 0]\n",
       "Name: pct_change_cat, Length: 12133, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df = pd.DataFrame(targets)\n",
    "targets_df[\"DATE\"] = [i[0].isoformat(sep=' ').split()[0] for i in targets]\n",
    "# targets_df = targets_df.iloc[:,1:].groupby(['DATE'], as_index=True)\n",
    "# targets_df.columns = [\"pct_change_cat\"]\n",
    "targets_df.columns = [\"full_ts\", \"pct_change_cat\", \"DATE\"]\n",
    "targets_df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(all_text)\n",
    "encoded_docs = tokenizer.texts_to_matrix(all_text, mode='tfidf')\n",
    "tfidf_df = pd.DataFrame(encoded_docs)\n",
    "# tfidf_df[\"DATE\"] = dates\n",
    "# tfidf_docs = tfidf_df.groupby(['DATE'], as_index=True).mean()\n",
    "# tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12132, 1, 500)\n",
      "(12132, 3)\n",
      "x_train (9705, 1, 500)\n",
      "y_train (9705, 3)\n",
      "x_test (2427, 1, 500)\n",
      "y_test (2427, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "X = tfidf_df.as_matrix()\n",
    "# y = targets_df.as_matrix() # predict current\n",
    "y = targets_df.iloc[:,1].shift(-1).dropna().as_matrix().reshape(-1,1) # predict next day\n",
    "\n",
    "X = np.array([[i] for i in X]) # for batch size 1\n",
    "X = X[1:]\n",
    "y = np.array([i[0] for i in y])\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(batch_input_shape=(1, 1, 500..., return_sequences=True, stateful=True, units=300)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compilation time :  0.0242159366607666\n"
     ]
    }
   ],
   "source": [
    "LAYERS = 300\n",
    "model = Sequential()\n",
    "\n",
    "# Original Architecture\n",
    "# model.add(Dense(\n",
    "#     input_dim=x_train.shape[1],\n",
    "#     output_dim=LAYERS))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(\n",
    "#     input_dim=x_train.shape[1],\n",
    "#     output_dim=LAYERS))\n",
    "# #model.add(Dense(output_dim = y_train.shape[1]))\n",
    "# model.add(Dense(output_dim=y_train.shape[1]))\n",
    "# model.add(Activation('linear'))\n",
    "\n",
    "# Stateful LSTM Architecture\n",
    "model.add(LSTM(\n",
    "    batch_input_shape=(1, 1, 500),\n",
    "    output_dim=LAYERS,\n",
    "    return_sequences=True,\n",
    "    stateful=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(\n",
    "    LAYERS,\n",
    "    return_sequences=False,\n",
    "    stateful=True))\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Dense(output_dim=y_train.shape[1]))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "start = time.time()\n",
    "adam = keras.optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam)\n",
    "print('compilation time : ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8734 samples, validate on 971 samples\n",
      "Epoch 1/5000\n",
      "8734/8734 [==============================] - 235s 27ms/step - loss: 2.9105 - val_loss: 2.8855\n",
      "Epoch 2/5000\n",
      "6996/8734 [=======================>......] - ETA: 48s - loss: 2.9260"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-02c6bc40f2d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALIDATIONSIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreduce_lr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlyStopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcp_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtbrd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResetStatesCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     shuffle=False)\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MODELNAME = 'briefing_nextday_stateful_lstm_softmax'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=6, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('./models/'+MODELNAME+'_best.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, epsilon=1e-4, mode='min')\n",
    "tbrd = TensorBoard(log_dir=\"./logs\", histogram_freq=0, batch_size=128, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "\n",
    "max_len = 20\n",
    "class ResetStatesCallback(Callback):\n",
    "    def __init__(self):\n",
    "        self.counter = 0\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        if self.counter % max_len == 0:\n",
    "            self.model.reset_states()\n",
    "        self.counter += 1\n",
    "\n",
    "VALIDATIONSIZE = 0.10\n",
    "EPOCHS = 5000\n",
    "# model = keras.models.load_model('./models/'+MODELNAME+'_best.hdf5') \n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=1,\n",
    "    nb_epoch=EPOCHS,\n",
    "    validation_split=VALIDATIONSIZE,\n",
    "    callbacks = [reduce_lr_loss, earlyStopping, mcp_save, tbrd, ResetStatesCallback()],\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write callback that looks for loss below threshold and that loss and val_loss are less than 0.01 difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 2s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9353546145132183"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.evaluate(x_test, y_test)\n",
    "model.evaluate(x_test, y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 3s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.884816817182455"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('./models/'+MODELNAME+'_best.hdf5') \n",
    "# model.evaluate(x_test, y_test)\n",
    "model.evaluate(x_test, y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14092773]]\n",
      "[[0.14935726]]\n",
      " \n",
      "[[0.10491294]]\n",
      "[[0.08785099]]\n",
      "[[0.08546847]]\n",
      " \n",
      "[[0.0851447]]\n",
      "[[0.16033787]]\n",
      "[[0.6232299]]\n",
      "[[0.2937979]]\n",
      "[[0.16033787]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# print(model.predict(tfidf_docs.loc[\"2016-01-06\"].as_matrix().reshape(1,-1))) # known down day\n",
    "# print(model.predict(tfidf_docs.loc[\"2016-03-09\"].as_matrix().reshape(1,-1))) # known up day\n",
    "print(model.predict(np.array([tfidf_docs.loc[\"2016-01-06\"].as_matrix().reshape(1,-1)])))\n",
    "print(model.predict(np.array([tfidf_docs.loc[\"2016-03-09\"].as_matrix().reshape(1,-1)])))\n",
    "\n",
    "def predict_based_on_text(text):\n",
    "#     return model.predict(tokenizer.texts_to_matrix([text]).reshape(1,-1))\n",
    "    return model.predict(np.array([tokenizer.texts_to_matrix([text]).reshape(1,-1)]))\n",
    "\n",
    "print(\" \")\n",
    "print(predict_based_on_text(\"U.S. dollar index weakens\"))\n",
    "print(predict_based_on_text(\"trade talks begin\"))\n",
    "print(predict_based_on_text(\"crude oil miss\"))\n",
    "\n",
    "# 6/14\n",
    "print(\" \")\n",
    "print(predict_based_on_text(\"Large Cap Underperformance Weighs On Dow\"))\n",
    "print(predict_based_on_text(\"Wall Street slips on semiconductor weakness\"))\n",
    "print(predict_based_on_text(\"FAANG stocks trade mixed\"))\n",
    "print(predict_based_on_text(\"Amazon underpinning resiliency in stock market this week\"))\n",
    "print(predict_based_on_text(\"Facebook gains on crypto plans\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
