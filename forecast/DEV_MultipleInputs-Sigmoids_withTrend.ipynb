{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.models import *\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import signal\n",
    "import stldecompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>XLE.Open</th>\n",
       "      <th>XLE.High</th>\n",
       "      <th>XLE.Low</th>\n",
       "      <th>XLE.Close</th>\n",
       "      <th>XLE.Volume</th>\n",
       "      <th>XLE.Adjusted</th>\n",
       "      <th>XLB.Open</th>\n",
       "      <th>XLB.High</th>\n",
       "      <th>XLB.Low</th>\n",
       "      <th>...</th>\n",
       "      <th>XLU.Low</th>\n",
       "      <th>XLU.Close</th>\n",
       "      <th>XLU.Volume</th>\n",
       "      <th>XLU.Adjusted</th>\n",
       "      <th>XLRE.Open</th>\n",
       "      <th>XLRE.High</th>\n",
       "      <th>XLRE.Low</th>\n",
       "      <th>XLRE.Close</th>\n",
       "      <th>XLRE.Volume</th>\n",
       "      <th>XLRE.Adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>63.759998</td>\n",
       "      <td>64.519997</td>\n",
       "      <td>63.700001</td>\n",
       "      <td>64.309998</td>\n",
       "      <td>20344700.0</td>\n",
       "      <td>64.309998</td>\n",
       "      <td>55.320000</td>\n",
       "      <td>56.080002</td>\n",
       "      <td>55.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>57.860001</td>\n",
       "      <td>57.980000</td>\n",
       "      <td>13389500.0</td>\n",
       "      <td>57.980000</td>\n",
       "      <td>36.189999</td>\n",
       "      <td>36.340000</td>\n",
       "      <td>35.970001</td>\n",
       "      <td>36.200001</td>\n",
       "      <td>3377200</td>\n",
       "      <td>36.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>63.549999</td>\n",
       "      <td>63.799999</td>\n",
       "      <td>62.939999</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>15064500.0</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>55.330002</td>\n",
       "      <td>55.430000</td>\n",
       "      <td>54.590000</td>\n",
       "      <td>...</td>\n",
       "      <td>57.529999</td>\n",
       "      <td>57.799999</td>\n",
       "      <td>12542200.0</td>\n",
       "      <td>57.799999</td>\n",
       "      <td>36.080002</td>\n",
       "      <td>36.139999</td>\n",
       "      <td>35.320000</td>\n",
       "      <td>35.580002</td>\n",
       "      <td>3711800</td>\n",
       "      <td>35.580002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>63.720001</td>\n",
       "      <td>64.279999</td>\n",
       "      <td>63.580002</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>9823700.0</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>54.840000</td>\n",
       "      <td>55.090000</td>\n",
       "      <td>54.599998</td>\n",
       "      <td>...</td>\n",
       "      <td>56.959999</td>\n",
       "      <td>57.009998</td>\n",
       "      <td>28692400.0</td>\n",
       "      <td>57.009998</td>\n",
       "      <td>35.650002</td>\n",
       "      <td>35.919998</td>\n",
       "      <td>35.564999</td>\n",
       "      <td>35.580002</td>\n",
       "      <td>3831500</td>\n",
       "      <td>35.580002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>63.450001</td>\n",
       "      <td>63.990002</td>\n",
       "      <td>62.910000</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>14409500.0</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>54.209999</td>\n",
       "      <td>54.610001</td>\n",
       "      <td>53.779999</td>\n",
       "      <td>...</td>\n",
       "      <td>56.660000</td>\n",
       "      <td>56.939999</td>\n",
       "      <td>16173800.0</td>\n",
       "      <td>56.939999</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>35.740002</td>\n",
       "      <td>35.259998</td>\n",
       "      <td>35.700001</td>\n",
       "      <td>5684500</td>\n",
       "      <td>35.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>64.209999</td>\n",
       "      <td>62.849998</td>\n",
       "      <td>64.050003</td>\n",
       "      <td>13073400.0</td>\n",
       "      <td>64.050003</td>\n",
       "      <td>54.299999</td>\n",
       "      <td>55.340000</td>\n",
       "      <td>54.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>56.820000</td>\n",
       "      <td>57.959999</td>\n",
       "      <td>25157000.0</td>\n",
       "      <td>57.959999</td>\n",
       "      <td>35.619999</td>\n",
       "      <td>36.200001</td>\n",
       "      <td>35.595001</td>\n",
       "      <td>36.110001</td>\n",
       "      <td>3268400</td>\n",
       "      <td>36.110001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Index   XLE.Open   XLE.High    XLE.Low  XLE.Close  XLE.Volume  \\\n",
       "3105  2019-05-06  63.759998  64.519997  63.700001  64.309998  20344700.0   \n",
       "3106  2019-05-07  63.549999  63.799999  62.939999  63.750000  15064500.0   \n",
       "3107  2019-05-08  63.720001  64.279999  63.580002  63.750000   9823700.0   \n",
       "3108  2019-05-09  63.450001  63.990002  62.910000  63.750000  14409500.0   \n",
       "3109  2019-05-10  63.750000  64.209999  62.849998  64.050003  13073400.0   \n",
       "\n",
       "      XLE.Adjusted   XLB.Open   XLB.High    XLB.Low      ...          XLU.Low  \\\n",
       "3105     64.309998  55.320000  56.080002  55.320000      ...        57.860001   \n",
       "3106     63.750000  55.330002  55.430000  54.590000      ...        57.529999   \n",
       "3107     63.750000  54.840000  55.090000  54.599998      ...        56.959999   \n",
       "3108     63.750000  54.209999  54.610001  53.779999      ...        56.660000   \n",
       "3109     64.050003  54.299999  55.340000  54.070000      ...        56.820000   \n",
       "\n",
       "      XLU.Close  XLU.Volume  XLU.Adjusted  XLRE.Open  XLRE.High   XLRE.Low  \\\n",
       "3105  57.980000  13389500.0     57.980000  36.189999  36.340000  35.970001   \n",
       "3106  57.799999  12542200.0     57.799999  36.080002  36.139999  35.320000   \n",
       "3107  57.009998  28692400.0     57.009998  35.650002  35.919998  35.564999   \n",
       "3108  56.939999  16173800.0     56.939999  35.500000  35.740002  35.259998   \n",
       "3109  57.959999  25157000.0     57.959999  35.619999  36.200001  35.595001   \n",
       "\n",
       "      XLRE.Close  XLRE.Volume  XLRE.Adjusted  \n",
       "3105   36.200001      3377200      36.200001  \n",
       "3106   35.580002      3711800      35.580002  \n",
       "3107   35.580002      3831500      35.580002  \n",
       "3108   35.700001      5684500      35.700001  \n",
       "3109   36.110001      3268400      36.110001  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_orig = pd.read_csv('../data/files/multiple_concatenated_tickers.csv')\n",
    "data_orig.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import *\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "def df_from_fred(setname):\n",
    "    # Make GET Request\n",
    "    response = urlopen(url_for(setname))\n",
    "    # Read response data\n",
    "    data = response.read()\n",
    "    # Convert binary text to utf-8\n",
    "    text = data.decode('utf-8')\n",
    "    # Convert text file to pandas dataframe\n",
    "    TEXTDATA = StringIO(text)\n",
    "    df = pd.read_csv(TEXTDATA, sep=\",\")\n",
    "    return df\n",
    "\n",
    "def url_for(series):\n",
    "    \"\"\"function takes FRED series name as input. For example, GDPC1, or HOUST.\"\"\"\n",
    "    return \"https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=968&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=\"+series+\"&scale=left&cosd=1947-01-01&coed=2019-01-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Quarterly&fam=avg&fgst=lin&fgsnd=2009-06-01&line_index=1&transformation=lin&vintage_date=2019-05-07&revision_date=2019-05-07&nd=1947-01-01\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vital Economic indicators: https://gist.github.com/ngopal/262fce10a7fa4a8467f0c61a13c85dc5\n",
    "GDPC1 = df_from_fred(\"GDPC1\")\n",
    "time.sleep(5)\n",
    "M2 = df_from_fred(\"M2\")\n",
    "time.sleep(5)\n",
    "CPALTT01USQ657N = df_from_fred(\"CPALTT01USQ657N\")\n",
    "time.sleep(5)\n",
    "PPIACO = df_from_fred(\"PPIACO\")\n",
    "time.sleep(5)\n",
    "UMCSENT = df_from_fred(\"UMCSENT\")\n",
    "time.sleep(5)\n",
    "PAYEMS = df_from_fred(\"PAYEMS\")\n",
    "time.sleep(5)\n",
    "RRSFS = df_from_fred(\"RRSFS\")\n",
    "time.sleep(5)\n",
    "HOUST = df_from_fred(\"HOUST\")\n",
    "time.sleep(5)\n",
    "ISRATIO = df_from_fred(\"ISRATIO\")\n",
    "time.sleep(5)\n",
    "SP500 = df_from_fred(\"SP500\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Others\n",
    "IPMAN = df_from_fred(\"IPMAN\")\n",
    "time.sleep(5)\n",
    "MPU9900063 = df_from_fred(\"MPU9900063\")\n",
    "time.sleep(5)\n",
    "PCU33443344 = df_from_fred(\"PCU33443344\")\n",
    "time.sleep(5)\n",
    "MEHOINUSA672N = df_from_fred(\"MEHOINUSA672N\")\n",
    "time.sleep(5)\n",
    "TCMDO = df_from_fred(\"TCMDO\")\n",
    "time.sleep(5)\n",
    "FGTCMDODNS = df_from_fred(\"FGTCMDODNS\")\n",
    "time.sleep(5)\n",
    "ADSLFAA027N = df_from_fred(\"ADSLFAA027N\")\n",
    "time.sleep(5)\n",
    "NCBCMDPMVCE = df_from_fred(\"NCBCMDPMVCE\")\n",
    "time.sleep(5)\n",
    "FGCCSAQ027S = df_from_fred(\"FGCCSAQ027S\")\n",
    "time.sleep(5)\n",
    "ASTNITA = df_from_fred(\"ASTNITA\")\n",
    "time.sleep(5)\n",
    "PCETRIM12M159SFRBDAL = df_from_fred(\"PCETRIM12M159SFRBDAL\")\n",
    "\n",
    "# IPMAN, MPU9900063, PCU33443344, MEHOINUSA672N, TCMDO, FGTCMDODNS, ADSLFAA027N, NCBCMDPMVCE, FGCCSAQ027S, ASTNITA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig = data_orig\\\n",
    "  .merge(GDPC1, how=\"left\", left_on=data_orig.Index, right_on=GDPC1.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(M2, how=\"left\", left_on=data_orig.Index, right_on=M2.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(CPALTT01USQ657N, how=\"left\", left_on=data_orig.Index, right_on=CPALTT01USQ657N.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(PPIACO, how=\"left\", left_on=data_orig.Index, right_on=PPIACO.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(UMCSENT, how=\"left\", left_on=data_orig.Index, right_on=UMCSENT.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(PAYEMS, how=\"left\", left_on=data_orig.Index, right_on=PAYEMS.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(RRSFS, how=\"left\", left_on=data_orig.Index, right_on=RRSFS.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(HOUST, how=\"left\", left_on=data_orig.Index, right_on=HOUST.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(ISRATIO, how=\"left\", left_on=data_orig.Index, right_on=ISRATIO.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(PCETRIM12M159SFRBDAL, how=\"left\", left_on=data_orig.Index, right_on=PCETRIM12M159SFRBDAL.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(ASTNITA, how=\"left\", left_on=data_orig.Index, right_on=ASTNITA.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(FGCCSAQ027S, how=\"left\", left_on=data_orig.Index, right_on=FGCCSAQ027S.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(NCBCMDPMVCE, how=\"left\", left_on=data_orig.Index, right_on=NCBCMDPMVCE.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(ADSLFAA027N, how=\"left\", left_on=data_orig.Index, right_on=ADSLFAA027N.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(FGTCMDODNS, how=\"left\", left_on=data_orig.Index, right_on=FGTCMDODNS.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(TCMDO, how=\"left\", left_on=data_orig.Index, right_on=TCMDO.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(MEHOINUSA672N, how=\"left\", left_on=data_orig.Index, right_on=MEHOINUSA672N.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(PCU33443344, how=\"left\", left_on=data_orig.Index, right_on=PCU33443344.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(MPU9900063, how=\"left\", left_on=data_orig.Index, right_on=MPU9900063.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(IPMAN, how=\"left\", left_on=data_orig.Index, right_on=IPMAN.DATE).fillna(method=\"ffill\")\\\n",
    "  .drop(\"key_0\", axis=1)\\\n",
    "  .merge(SP500, how=\"left\", left_on=data_orig.Index, right_on=SP500.DATE).fillna(method=\"ffill\")\\\n",
    "  .fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig.drop(['DATE_y', 'DATE_x', 'key_0', 'DATE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Index',\n",
       " 'XLE.Open',\n",
       " 'XLE.High',\n",
       " 'XLE.Low',\n",
       " 'XLE.Close',\n",
       " 'XLE.Volume',\n",
       " 'XLE.Adjusted',\n",
       " 'XLB.Open',\n",
       " 'XLB.High',\n",
       " 'XLB.Low',\n",
       " 'XLB.Close',\n",
       " 'XLB.Volume',\n",
       " 'XLB.Adjusted',\n",
       " 'XLI.Open',\n",
       " 'XLI.High',\n",
       " 'XLI.Low',\n",
       " 'XLI.Close',\n",
       " 'XLI.Volume',\n",
       " 'XLI.Adjusted',\n",
       " 'XLY.Open',\n",
       " 'XLY.High',\n",
       " 'XLY.Low',\n",
       " 'XLY.Close',\n",
       " 'XLY.Volume',\n",
       " 'XLY.Adjusted',\n",
       " 'XLP.Open',\n",
       " 'XLP.High',\n",
       " 'XLP.Low',\n",
       " 'XLP.Close',\n",
       " 'XLP.Volume',\n",
       " 'XLP.Adjusted',\n",
       " 'XLV.Open',\n",
       " 'XLV.High',\n",
       " 'XLV.Low',\n",
       " 'XLV.Close',\n",
       " 'XLV.Volume',\n",
       " 'XLV.Adjusted',\n",
       " 'XLF.Open',\n",
       " 'XLF.High',\n",
       " 'XLF.Low',\n",
       " 'XLF.Close',\n",
       " 'XLF.Volume',\n",
       " 'XLF.Adjusted',\n",
       " 'XLK.Open',\n",
       " 'XLK.High',\n",
       " 'XLK.Low',\n",
       " 'XLK.Close',\n",
       " 'XLK.Volume',\n",
       " 'XLK.Adjusted',\n",
       " 'XTL.Open',\n",
       " 'XTL.High',\n",
       " 'XTL.Low',\n",
       " 'XTL.Close',\n",
       " 'XTL.Volume',\n",
       " 'XTL.Adjusted',\n",
       " 'XLU.Open',\n",
       " 'XLU.High',\n",
       " 'XLU.Low',\n",
       " 'XLU.Close',\n",
       " 'XLU.Volume',\n",
       " 'XLU.Adjusted',\n",
       " 'XLRE.Open',\n",
       " 'XLRE.High',\n",
       " 'XLRE.Low',\n",
       " 'XLRE.Close',\n",
       " 'XLRE.Volume',\n",
       " 'XLRE.Adjusted',\n",
       " 'GDPC1',\n",
       " 'M2',\n",
       " 'CPALTT01USQ657N',\n",
       " 'PPIACO',\n",
       " 'UMCSENT',\n",
       " 'PAYEMS',\n",
       " 'RRSFS',\n",
       " 'HOUST',\n",
       " 'ISRATIO',\n",
       " 'PCETRIM12M159SFRBDAL',\n",
       " 'ASTNITA',\n",
       " 'FGCCSAQ027S',\n",
       " 'NCBCMDPMVCE',\n",
       " 'ADSLFAA027N',\n",
       " 'FGTCMDODNS',\n",
       " 'TCMDO',\n",
       " 'MEHOINUSA672N',\n",
       " 'PCU33443344',\n",
       " 'MPU9900063',\n",
       " 'IPMAN',\n",
       " 'SP500']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_orig.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XLB': 7,\n",
       " 'XLE': 1,\n",
       " 'XLF': 37,\n",
       " 'XLI': 13,\n",
       " 'XLK': 43,\n",
       " 'XLP': 25,\n",
       " 'XLRE': 61,\n",
       " 'XLU': 55,\n",
       " 'XLV': 31,\n",
       " 'XLY': 19,\n",
       " 'XTL': 49}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_lookup = dict([(i[1].split('.')[0], int(i[0])) for i in enumerate(list(data_orig.columns)) if 'Open' in i[1]])\n",
    "ticker_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHOSENTICKER = 'QQQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "days_lookback = 1\n",
    "theta = 0.05 # This needs to go between pct_change and argmax apply\n",
    "# pct_df = data_orig.iloc[:,list(ticker_lookup.values())].pct_change(days_lookback).apply(lambda y: y.argmax(), axis=1).fillna(\"GSPC.Open\")\n",
    "pct_df = data_orig.iloc[:,list(ticker_lookup.values())].pct_change(days_lookback).apply(lambda y: y.argmax(), axis=1).fillna(\"XLV.Open\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5\n",
       "1        9\n",
       "2        7\n",
       "3        0\n",
       "4        2\n",
       "5        4\n",
       "6        7\n",
       "7        5\n",
       "8        1\n",
       "9        2\n",
       "10       0\n",
       "11       3\n",
       "12       0\n",
       "13       4\n",
       "14       2\n",
       "15       1\n",
       "16       9\n",
       "17       4\n",
       "18       2\n",
       "19       0\n",
       "20       2\n",
       "21       0\n",
       "22       2\n",
       "23       9\n",
       "24       7\n",
       "25       3\n",
       "26       0\n",
       "27       9\n",
       "28       1\n",
       "29       2\n",
       "        ..\n",
       "3080     0\n",
       "3081     1\n",
       "3082     6\n",
       "3083     1\n",
       "3084     8\n",
       "3085     2\n",
       "3086     0\n",
       "3087     4\n",
       "3088     8\n",
       "3089     8\n",
       "3090     2\n",
       "3091     8\n",
       "3092     5\n",
       "3093     6\n",
       "3094     4\n",
       "3095     2\n",
       "3096     0\n",
       "3097     5\n",
       "3098     7\n",
       "3099     9\n",
       "3100     6\n",
       "3101     0\n",
       "3102     9\n",
       "3103    10\n",
       "3104     3\n",
       "3105     9\n",
       "3106     5\n",
       "3107     0\n",
       "3108     4\n",
       "3109     0\n",
       "Length: 3110, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_map = {v+'.Open': k for k, v in dict(enumerate(list(ticker_lookup.keys()))).items()}\n",
    "pct_df.map(lambda x: inv_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De-trend data\n",
    "data_orig_detrended = signal.detrend(data_orig.iloc[:,1:])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# data_mat = scaler.fit_transform(data_orig.iloc[:,1:])\n",
    "data_mat = scaler.fit_transform(data_orig_detrended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 180 # days to use for prediction\n",
    "data = np.array((data_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_length = seq_len + 1\n",
    "result = []\n",
    "for index in range(len(data) - sequence_length):\n",
    "    result.append(data[index: index + sequence_length])\n",
    "\n",
    "result = np.array(result)\n",
    "\n",
    "row = round(0.9 * result.shape[0])\n",
    "train = result[:int(row), :] # Create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[0.90389554, 0.90497316, 0.90606556, ..., 0.98592183,\n",
       "          0.98558089, 0.98523309],\n",
       "         [0.90289468, 0.90405911, 0.90523959, ..., 1.        ,\n",
       "          1.        , 1.        ],\n",
       "         [0.92175623, 0.92270919, 0.92367526, ..., 0.98024238,\n",
       "          0.97933002, 0.97839891],\n",
       "         ...,\n",
       "         [0.82686532, 0.82721261, 0.8275645 , ..., 0.7918213 ,\n",
       "          0.7890371 , 0.78619893],\n",
       "         [0.8797671 , 0.88028202, 0.880804  , ..., 0.86755909,\n",
       "          0.86516048, 0.86271435],\n",
       "         [0.89495498, 0.89549314, 0.8960387 , ..., 0.88501263,\n",
       "          0.88262839, 0.88019656]],\n",
       " \n",
       "        [[0.90289468, 0.90405911, 0.90523959, ..., 1.        ,\n",
       "          1.        , 1.        ],\n",
       "         [0.92175623, 0.92270919, 0.92367526, ..., 0.98024238,\n",
       "          0.97933002, 0.97839891],\n",
       "         [0.94274806, 0.94354057, 0.94434396, ..., 0.9711683 ,\n",
       "          0.9695305 , 0.9678589 ],\n",
       "         ...,\n",
       "         [0.8797671 , 0.88028202, 0.880804  , ..., 0.86755909,\n",
       "          0.86516048, 0.86271435],\n",
       "         [0.89495498, 0.89549314, 0.8960387 , ..., 0.88501263,\n",
       "          0.88262839, 0.88019656],\n",
       "         [0.937555  , 0.93778251, 0.93801313, ..., 0.86917508,\n",
       "          0.86537652, 0.86150097]],\n",
       " \n",
       "        [[0.92175623, 0.92270919, 0.92367526, ..., 0.98024238,\n",
       "          0.97933002, 0.97839891],\n",
       "         [0.94274806, 0.94354057, 0.94434396, ..., 0.9711683 ,\n",
       "          0.9695305 , 0.9678589 ],\n",
       "         [0.9340065 , 0.93486283, 0.93573092, ..., 0.97442737,\n",
       "          0.97307999, 0.97170485],\n",
       "         ...,\n",
       "         [0.89495498, 0.89549314, 0.8960387 , ..., 0.88501263,\n",
       "          0.88262839, 0.88019656],\n",
       "         [0.937555  , 0.93778251, 0.93801313, ..., 0.86917508,\n",
       "          0.86537652, 0.86150097],\n",
       "         [0.91553688, 0.91600253, 0.91647458, ..., 0.89073475,\n",
       "          0.88796745, 0.88514438]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.92069733, 0.920657  , 0.9206161 , ..., 0.80808492,\n",
       "          0.80334457, 0.79871819],\n",
       "         [0.92599185, 0.92620332, 0.92641769, ..., 0.85617744,\n",
       "          0.85238522, 0.84872586],\n",
       "         [0.88636499, 0.88683651, 0.88731448, ..., 0.86592287,\n",
       "          0.86333432, 0.86090371],\n",
       "         ...,\n",
       "         [0.87256888, 0.87293411, 0.8733043 , ..., 0.83538102,\n",
       "          0.83244966, 0.8296697 ],\n",
       "         [0.874204  , 0.87444039, 0.87468002, ..., 0.81462693,\n",
       "          0.81118898, 0.80789223],\n",
       "         [0.91291267, 0.91285064, 0.9127877 , ..., 0.7974495 ,\n",
       "          0.79266385, 0.78799145]],\n",
       " \n",
       "        [[0.92599185, 0.92620332, 0.92641769, ..., 0.85617744,\n",
       "          0.85238522, 0.84872586],\n",
       "         [0.88636499, 0.88683651, 0.88731448, ..., 0.86592287,\n",
       "          0.86333432, 0.86090371],\n",
       "         [0.91628575, 0.91640774, 0.91653138, ..., 0.83215805,\n",
       "          0.82806781, 0.82410467],\n",
       "         ...,\n",
       "         [0.874204  , 0.87444039, 0.87468002, ..., 0.81462693,\n",
       "          0.81118898, 0.80789223],\n",
       "         [0.91291267, 0.91285064, 0.9127877 , ..., 0.7974495 ,\n",
       "          0.79266385, 0.78799145],\n",
       "         [0.92805955, 0.92814881, 0.92823929, ..., 0.83694146,\n",
       "          0.83266598, 0.82851363]],\n",
       " \n",
       "        [[0.88636499, 0.88683651, 0.88731448, ..., 0.86592287,\n",
       "          0.86333432, 0.86090371],\n",
       "         [0.91628575, 0.91640774, 0.91653138, ..., 0.83215805,\n",
       "          0.82806781, 0.82410467],\n",
       "         [0.89572351, 0.89569017, 0.89565634, ..., 0.78717891,\n",
       "          0.78258988, 0.77811847],\n",
       "         ...,\n",
       "         [0.91291267, 0.91285064, 0.9127877 , ..., 0.7974495 ,\n",
       "          0.79266385, 0.78799145],\n",
       "         [0.92805955, 0.92814881, 0.92823929, ..., 0.83694146,\n",
       "          0.83266598, 0.82851363],\n",
       "         [0.90895726, 0.90911816, 0.90928124, ..., 0.83237496,\n",
       "          0.82847172, 0.82469953]]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[[0.91628575, 0.91640774, 0.91653138, ..., 0.83215805,\n",
       "          0.82806781, 0.82410467],\n",
       "         [0.89572351, 0.89569017, 0.89565634, ..., 0.78717891,\n",
       "          0.78258988, 0.77811847],\n",
       "         [0.91971057, 0.91982434, 0.91993968, ..., 0.83377632,\n",
       "          0.82963729, 0.82562431],\n",
       "         ...,\n",
       "         [0.92805955, 0.92814881, 0.92823929, ..., 0.83694146,\n",
       "          0.83266598, 0.82851363],\n",
       "         [0.90895726, 0.90911816, 0.90928124, ..., 0.83237496,\n",
       "          0.82847172, 0.82469953],\n",
       "         [0.92223175, 0.92224013, 0.92224859, ..., 0.81783672,\n",
       "          0.81327717, 0.80883518]],\n",
       " \n",
       "        [[0.89572351, 0.89569017, 0.89565634, ..., 0.78717891,\n",
       "          0.78258988, 0.77811847],\n",
       "         [0.91971057, 0.91982434, 0.91993968, ..., 0.83377632,\n",
       "          0.82963729, 0.82562431],\n",
       "         [0.90161822, 0.90171318, 0.90180943, ..., 0.81451515,\n",
       "          0.81039334, 0.80639837],\n",
       "         ...,\n",
       "         [0.90895726, 0.90911816, 0.90928124, ..., 0.83237496,\n",
       "          0.82847172, 0.82469953],\n",
       "         [0.92223175, 0.92224013, 0.92224859, ..., 0.81783672,\n",
       "          0.81327717, 0.80883518],\n",
       "         [0.91518493, 0.91525177, 0.91531948, ..., 0.82167707,\n",
       "          0.81737888, 0.81320366]],\n",
       " \n",
       "        [[0.91971057, 0.91982434, 0.91993968, ..., 0.83377632,\n",
       "          0.82963729, 0.82562431],\n",
       "         [0.90161822, 0.90171318, 0.90180943, ..., 0.81451515,\n",
       "          0.81039334, 0.80639837],\n",
       "         [0.88508748, 0.88522162, 0.88535758, ..., 0.80663243,\n",
       "          0.8027445 , 0.79898849],\n",
       "         ...,\n",
       "         [0.92223175, 0.92224013, 0.92224859, ..., 0.81783672,\n",
       "          0.81327717, 0.80883518],\n",
       "         [0.91518493, 0.91525177, 0.91531948, ..., 0.82167707,\n",
       "          0.81737888, 0.81320366],\n",
       "         [0.90442177, 0.9044669 , 0.90451263, ..., 0.80840841,\n",
       "          0.80407982, 0.79987386]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.88507677, 0.88552362, 0.88597663, ..., 0.86052888,\n",
       "          0.85785126, 0.85532982],\n",
       "         [0.91961082, 0.91979656, 0.91998487, ..., 0.84609248,\n",
       "          0.84223244, 0.83850406],\n",
       "         [0.94075446, 0.9408997 , 0.94104691, ..., 0.8578245 ,\n",
       "          0.85370237, 0.84970611],\n",
       "         ...,\n",
       "         [0.89761757, 0.89795857, 0.89830425, ..., 0.85338394,\n",
       "          0.85023484, 0.84728828],\n",
       "         [0.86722921, 0.86776558, 0.86830931, ..., 0.86015848,\n",
       "          0.85791674, 0.85589646],\n",
       "         [0.85415447, 0.85455846, 0.85496802, ..., 0.82577034,\n",
       "          0.82308151, 0.82060549]],\n",
       " \n",
       "        [[0.91961082, 0.91979656, 0.91998487, ..., 0.84609248,\n",
       "          0.84223244, 0.83850406],\n",
       "         [0.94075446, 0.9408997 , 0.94104691, ..., 0.8578245 ,\n",
       "          0.85370237, 0.84970611],\n",
       "         [0.92460822, 0.92474496, 0.92488358, ..., 0.84206916,\n",
       "          0.83799459, 0.83404725],\n",
       "         ...,\n",
       "         [0.86722921, 0.86776558, 0.86830931, ..., 0.86015848,\n",
       "          0.85791674, 0.85589646],\n",
       "         [0.85415447, 0.85455846, 0.85496802, ..., 0.82577034,\n",
       "          0.82308151, 0.82060549],\n",
       "         [0.90261845, 0.90261621, 0.90261391, ..., 0.79864411,\n",
       "          0.79414175, 0.78981469]],\n",
       " \n",
       "        [[0.94075446, 0.9408997 , 0.94104691, ..., 0.8578245 ,\n",
       "          0.85370237, 0.84970611],\n",
       "         [0.92460822, 0.92474496, 0.92488358, ..., 0.84206916,\n",
       "          0.83799459, 0.83404725],\n",
       "         [0.94844481, 0.94858003, 0.94871708, ..., 0.86290394,\n",
       "          0.85870471, 0.85462963],\n",
       "         ...,\n",
       "         [0.85415447, 0.85455846, 0.85496802, ..., 0.82577034,\n",
       "          0.82308151, 0.82060549],\n",
       "         [0.90261845, 0.90261621, 0.90261391, ..., 0.79864411,\n",
       "          0.79414175, 0.78981469],\n",
       "         [0.86910718, 0.86933934, 0.86957466, ..., 0.80938388,\n",
       "          0.80595552, 0.80272479]]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.random.shuffle(train)\n",
    "x_train = result[:int(row), :]\n",
    "y_train = to_categorical(pct_df.map(lambda x: inv_map[x]))[:int(row)]\n",
    "x_test = result[int(row):, :]\n",
    "y_test = to_categorical(pct_df.map(lambda x: inv_map[x]))[int(row):]\n",
    "\n",
    "[x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  import sys\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(return_sequences=True, input_shape=(None, 87), units=250)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compilation time :  0.022477149963378906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=11)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "LAYERS = 250\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(\n",
    "    input_dim=data.shape[1],\n",
    "    output_dim=LAYERS,\n",
    "    return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(\n",
    "    LAYERS,\n",
    "    return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(\n",
    "    output_dim=y_train.shape[1]))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "start = time.time()\n",
    "rmsprop = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rmsprop)\n",
    "print('compilation time : ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "MODELNAME = 'multiplemodeltest_withoutTrend5'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('./models/'+MODELNAME+'_best.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, epsilon=1e-4, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1977 samples, validate on 659 samples\n",
      "Epoch 1/500\n",
      "1977/1977 [==============================] - 54s 27ms/step - loss: 3.0718 - val_loss: 3.2157\n",
      "Epoch 2/500\n",
      "1977/1977 [==============================] - 42s 21ms/step - loss: 2.9962 - val_loss: 2.8025\n",
      "Epoch 3/500\n",
      "1977/1977 [==============================] - 42s 21ms/step - loss: 2.5113 - val_loss: 2.8656\n",
      "Epoch 4/500\n",
      "1977/1977 [==============================] - 42s 21ms/step - loss: 2.4116 - val_loss: 2.6719\n",
      "Epoch 5/500\n",
      "1977/1977 [==============================] - 43s 22ms/step - loss: 2.3595 - val_loss: 2.8557\n",
      "Epoch 6/500\n",
      "1977/1977 [==============================] - 42s 21ms/step - loss: 2.4172 - val_loss: 2.7252\n",
      "Epoch 7/500\n",
      "1977/1977 [==============================] - 41s 21ms/step - loss: 2.4132 - val_loss: 2.7230\n",
      "Epoch 8/500\n",
      "1977/1977 [==============================] - 45s 23ms/step - loss: 2.4347 - val_loss: 3.1206\n",
      "Epoch 9/500\n",
      "1977/1977 [==============================] - 45s 23ms/step - loss: 2.3660 - val_loss: 2.7698\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 10/500\n",
      "1977/1977 [==============================] - 63s 32ms/step - loss: 2.3288 - val_loss: 2.6461\n",
      "Epoch 11/500\n",
      "1977/1977 [==============================] - 62s 31ms/step - loss: 2.2762 - val_loss: 2.6372\n",
      "Epoch 12/500\n",
      "1977/1977 [==============================] - 60s 30ms/step - loss: 2.2757 - val_loss: 2.6406\n",
      "Epoch 13/500\n",
      "1977/1977 [==============================] - 59s 30ms/step - loss: 2.2705 - val_loss: 2.6360\n",
      "Epoch 14/500\n",
      "1977/1977 [==============================] - 49s 25ms/step - loss: 2.2883 - val_loss: 2.6881\n",
      "Epoch 15/500\n",
      "1977/1977 [==============================] - 45s 23ms/step - loss: 2.2662 - val_loss: 2.7402\n",
      "Epoch 16/500\n",
      "1977/1977 [==============================] - 43s 22ms/step - loss: 2.2858 - val_loss: 2.6262\n",
      "Epoch 17/500\n",
      "1977/1977 [==============================] - 45s 23ms/step - loss: 2.2546 - val_loss: 2.8249\n",
      "Epoch 18/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-68b4b34a3389>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALIDATIONSIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     callbacks = [reduce_lr_loss, earlyStopping, mcp_save])\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "VALIDATIONSIZE = 0.25\n",
    "EPOCHS = 500\n",
    "#model = keras.models.load_model('./models/'+MODELNAME+'_best.hdf5') \n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    nb_epoch=EPOCHS,\n",
    "    validation_split=VALIDATIONSIZE,\n",
    "    callbacks = [reduce_lr_loss, earlyStopping, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model('./models/'+MODELNAME+'_best.hdf5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5 refers to days of data. 5 days worth. each 1 row has 36 features\n",
    "days = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "dd = defaultdict(list)\n",
    "qq = defaultdict(list)\n",
    "for d in range(days):\n",
    "    li = []\n",
    "    for k in sorted(zip(list(ticker_lookup.keys()), best_model.predict(np.reshape(data[-days:], (days, 1, data.shape[1])))[d]), key = lambda x: x[1], reverse=True):\n",
    "        dd[k[0]].append(k[1])\n",
    "        li.append(k[0])\n",
    "    qq[d] = li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'XLB': [0.04184456,\n",
       "              0.041863076,\n",
       "              0.04106309,\n",
       "              0.04206508,\n",
       "              0.04133644],\n",
       "             'XLE': [0.08326638,\n",
       "              0.08020105,\n",
       "              0.07515742,\n",
       "              0.07786794,\n",
       "              0.07583557],\n",
       "             'XLF': [0.065611586,\n",
       "              0.068989694,\n",
       "              0.0682259,\n",
       "              0.06914187,\n",
       "              0.07051289],\n",
       "             'XLI': [0.1099016,\n",
       "              0.11430359,\n",
       "              0.110443875,\n",
       "              0.11404484,\n",
       "              0.11480905],\n",
       "             'XLK': [0.076793015,\n",
       "              0.07750136,\n",
       "              0.07787715,\n",
       "              0.077882156,\n",
       "              0.07706105],\n",
       "             'XLP': [0.16747765,\n",
       "              0.16745287,\n",
       "              0.17025185,\n",
       "              0.16866216,\n",
       "              0.17077981],\n",
       "             'XLRE': [0.21672858,\n",
       "              0.20919569,\n",
       "              0.2188561,\n",
       "              0.21019907,\n",
       "              0.20987685],\n",
       "             'XLU': [0.07752823,\n",
       "              0.080295,\n",
       "              0.07992086,\n",
       "              0.08033291,\n",
       "              0.081869595],\n",
       "             'XLV': [0.07259618,\n",
       "              0.0711361,\n",
       "              0.07184429,\n",
       "              0.070965394,\n",
       "              0.07001276],\n",
       "             'XLY': [0.05209483,\n",
       "              0.05422212,\n",
       "              0.050835807,\n",
       "              0.05381817,\n",
       "              0.053647883],\n",
       "             'XTL': [0.036157437,\n",
       "              0.034839425,\n",
       "              0.03552366,\n",
       "              0.035020377,\n",
       "              0.034258094]})"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['XLRE', 'XLP', 'XLI', 'XLE', 'XLU', 'XLK', 'XLV', 'XLF', 'XLY', 'XLB'],\n",
       " ['XLRE', 'XLP', 'XLI', 'XLU', 'XLE', 'XLK', 'XLV', 'XLF', 'XLY', 'XLB'],\n",
       " ['XLRE', 'XLP', 'XLI', 'XLU', 'XLK', 'XLE', 'XLV', 'XLF', 'XLY', 'XLB'],\n",
       " ['XLRE', 'XLP', 'XLI', 'XLU', 'XLK', 'XLE', 'XLV', 'XLF', 'XLY', 'XLB'],\n",
       " ['XLRE', 'XLP', 'XLI', 'XLU', 'XLK', 'XLE', 'XLF', 'XLV', 'XLY', 'XLB']]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[qq[i][:10] for i in range(days)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XLRE.Open', 'XLRE.Open', 'XLRE.Open', 'XLRE.Open', 'XLRE.Open']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_map = {v:k for k, v in inv_map.items()}\n",
    "# model.predict(np.reshape(data[-days:], (days, 1, data.shape[1])))[0].argmax()\n",
    "[lookup_map[best_model.predict(np.reshape(data[-days:], (days, 1, data.shape[1])))[i].argmax()] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([k for k in best_model.predict(np.reshape(data[-5:], (5, 1, data.shape[1])))])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
