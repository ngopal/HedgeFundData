{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.callbacks import *\n",
    "from keras.models import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>QQQ.Open</th>\n",
       "      <th>QQQ.High</th>\n",
       "      <th>QQQ.Low</th>\n",
       "      <th>QQQ.Close</th>\n",
       "      <th>QQQ.Volume</th>\n",
       "      <th>QQQ.Adjusted</th>\n",
       "      <th>TSLA.Open</th>\n",
       "      <th>TSLA.High</th>\n",
       "      <th>TSLA.Low</th>\n",
       "      <th>...</th>\n",
       "      <th>TNX.Low</th>\n",
       "      <th>TNX.Close</th>\n",
       "      <th>TNX.Volume</th>\n",
       "      <th>TNX.Adjusted</th>\n",
       "      <th>RYSDX.Open</th>\n",
       "      <th>RYSDX.High</th>\n",
       "      <th>RYSDX.Low</th>\n",
       "      <th>RYSDX.Close</th>\n",
       "      <th>RYSDX.Volume</th>\n",
       "      <th>RYSDX.Adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>186.570007</td>\n",
       "      <td>187.990005</td>\n",
       "      <td>186.429993</td>\n",
       "      <td>187.919998</td>\n",
       "      <td>17936000</td>\n",
       "      <td>187.919998</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>269.679993</td>\n",
       "      <td>262.480011</td>\n",
       "      <td>...</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.23</td>\n",
       "      <td>47944</td>\n",
       "      <td>1.23</td>\n",
       "      <td>52.619999</td>\n",
       "      <td>52.619999</td>\n",
       "      <td>52.619999</td>\n",
       "      <td>52.619999</td>\n",
       "      <td>0</td>\n",
       "      <td>52.619999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>2019-04-23</td>\n",
       "      <td>188.399994</td>\n",
       "      <td>190.539993</td>\n",
       "      <td>188.130005</td>\n",
       "      <td>190.309998</td>\n",
       "      <td>33665600</td>\n",
       "      <td>190.309998</td>\n",
       "      <td>260.149994</td>\n",
       "      <td>265.600006</td>\n",
       "      <td>255.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.19</td>\n",
       "      <td>16650</td>\n",
       "      <td>1.19</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>0</td>\n",
       "      <td>52.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>190.470001</td>\n",
       "      <td>190.710007</td>\n",
       "      <td>189.649994</td>\n",
       "      <td>189.710007</td>\n",
       "      <td>24977100</td>\n",
       "      <td>189.710007</td>\n",
       "      <td>263.850006</td>\n",
       "      <td>265.320007</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.19</td>\n",
       "      <td>30603</td>\n",
       "      <td>1.19</td>\n",
       "      <td>53.509998</td>\n",
       "      <td>53.509998</td>\n",
       "      <td>53.509998</td>\n",
       "      <td>53.509998</td>\n",
       "      <td>0</td>\n",
       "      <td>53.509998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>191.130005</td>\n",
       "      <td>191.220001</td>\n",
       "      <td>189.449997</td>\n",
       "      <td>190.479996</td>\n",
       "      <td>29517500</td>\n",
       "      <td>190.479996</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>246.070007</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.15</td>\n",
       "      <td>9100</td>\n",
       "      <td>1.15</td>\n",
       "      <td>53.660000</td>\n",
       "      <td>53.660000</td>\n",
       "      <td>53.660000</td>\n",
       "      <td>53.660000</td>\n",
       "      <td>0</td>\n",
       "      <td>53.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>190.179993</td>\n",
       "      <td>190.690002</td>\n",
       "      <td>188.589996</td>\n",
       "      <td>190.649994</td>\n",
       "      <td>26359500</td>\n",
       "      <td>190.649994</td>\n",
       "      <td>246.500000</td>\n",
       "      <td>246.679993</td>\n",
       "      <td>231.130005</td>\n",
       "      <td>...</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.15</td>\n",
       "      <td>12270</td>\n",
       "      <td>1.15</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>0</td>\n",
       "      <td>53.490002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Index    QQQ.Open    QQQ.High     QQQ.Low   QQQ.Close  QQQ.Volume  \\\n",
       "3095  2019-04-22  186.570007  187.990005  186.429993  187.919998    17936000   \n",
       "3096  2019-04-23  188.399994  190.539993  188.130005  190.309998    33665600   \n",
       "3097  2019-04-24  190.470001  190.710007  189.649994  189.710007    24977100   \n",
       "3098  2019-04-25  191.130005  191.220001  189.449997  190.479996    29517500   \n",
       "3099  2019-04-26  190.179993  190.690002  188.589996  190.649994    26359500   \n",
       "\n",
       "      QQQ.Adjusted   TSLA.Open   TSLA.High    TSLA.Low       ...        \\\n",
       "3095    187.919998  269.000000  269.679993  262.480011       ...         \n",
       "3096    190.309998  260.149994  265.600006  255.750000       ...         \n",
       "3097    189.710007  263.850006  265.320007  258.000000       ...         \n",
       "3098    190.479996  255.000000  259.000000  246.070007       ...         \n",
       "3099    190.649994  246.500000  246.679993  231.130005       ...         \n",
       "\n",
       "      TNX.Low  TNX.Close  TNX.Volume  TNX.Adjusted  RYSDX.Open  RYSDX.High  \\\n",
       "3095     1.14       1.23       47944          1.23   52.619999   52.619999   \n",
       "3096     1.19       1.19       16650          1.19   52.950001   52.950001   \n",
       "3097     1.13       1.19       30603          1.19   53.509998   53.509998   \n",
       "3098     1.12       1.15        9100          1.15   53.660000   53.660000   \n",
       "3099     1.13       1.15       12270          1.15   53.490002   53.490002   \n",
       "\n",
       "      RYSDX.Low  RYSDX.Close  RYSDX.Volume  RYSDX.Adjusted  \n",
       "3095  52.619999    52.619999             0       52.619999  \n",
       "3096  52.950001    52.950001             0       52.950001  \n",
       "3097  53.509998    53.509998             0       53.509998  \n",
       "3098  53.660000    53.660000             0       53.660000  \n",
       "3099  53.490002    53.490002             0       53.490002  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/files/multiple_concatenated_tickers.csv')\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAPL': 25,\n",
       " 'AMD': 67,\n",
       " 'AMZN': 37,\n",
       " 'DATA': 61,\n",
       " 'DIS': 145,\n",
       " 'DUK': 157,\n",
       " 'FB': 43,\n",
       " 'GLD': 175,\n",
       " 'HD': 151,\n",
       " 'INTC': 19,\n",
       " 'JNJ': 103,\n",
       " 'JWN': 91,\n",
       " 'KO': 109,\n",
       " 'MSFT': 13,\n",
       " 'NFLX': 31,\n",
       " 'NVDA': 127,\n",
       " 'PANW': 121,\n",
       " 'PG': 97,\n",
       " 'QQQ': 1,\n",
       " 'RHT': 133,\n",
       " 'RYSDX': 193,\n",
       " 'SBUX': 73,\n",
       " 'SLV': 181,\n",
       " 'SPOT': 163,\n",
       " 'SQ': 49,\n",
       " 'TGT': 85,\n",
       " 'TNX': 187,\n",
       " 'TSLA': 7,\n",
       " 'TWTR': 55,\n",
       " 'USO': 139,\n",
       " 'VRSN': 115,\n",
       " 'WDC': 169,\n",
       " 'WMT': 79}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_lookup = dict([(i[1].split('.')[0], int(i[0])) for i in enumerate(list(data.columns)) if 'Open' in i[1]])\n",
    "ticker_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHOSENTICKER = 'QQQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>QQQ.Open</th>\n",
       "      <th>QQQ.High</th>\n",
       "      <th>QQQ.Low</th>\n",
       "      <th>QQQ.Close</th>\n",
       "      <th>QQQ.Volume</th>\n",
       "      <th>QQQ.Adjusted</th>\n",
       "      <th>TSLA.Open</th>\n",
       "      <th>TSLA.High</th>\n",
       "      <th>TSLA.Low</th>\n",
       "      <th>...</th>\n",
       "      <th>TNX.Close</th>\n",
       "      <th>TNX.Volume</th>\n",
       "      <th>TNX.Adjusted</th>\n",
       "      <th>RYSDX.Open</th>\n",
       "      <th>RYSDX.High</th>\n",
       "      <th>RYSDX.Low</th>\n",
       "      <th>RYSDX.Close</th>\n",
       "      <th>RYSDX.Volume</th>\n",
       "      <th>RYSDX.Adjusted</th>\n",
       "      <th>tick_pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>186.570007</td>\n",
       "      <td>187.990005</td>\n",
       "      <td>186.429993</td>\n",
       "      <td>187.919998</td>\n",
       "      <td>17936000</td>\n",
       "      <td>187.919998</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>269.679993</td>\n",
       "      <td>262.480011</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23</td>\n",
       "      <td>47944</td>\n",
       "      <td>1.23</td>\n",
       "      <td>52.619999</td>\n",
       "      <td>52.619999</td>\n",
       "      <td>52.619999</td>\n",
       "      <td>52.619999</td>\n",
       "      <td>0</td>\n",
       "      <td>52.619999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>2019-04-23</td>\n",
       "      <td>188.399994</td>\n",
       "      <td>190.539993</td>\n",
       "      <td>188.130005</td>\n",
       "      <td>190.309998</td>\n",
       "      <td>33665600</td>\n",
       "      <td>190.309998</td>\n",
       "      <td>260.149994</td>\n",
       "      <td>265.600006</td>\n",
       "      <td>255.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.19</td>\n",
       "      <td>16650</td>\n",
       "      <td>1.19</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>0</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>190.470001</td>\n",
       "      <td>190.710007</td>\n",
       "      <td>189.649994</td>\n",
       "      <td>189.710007</td>\n",
       "      <td>24977100</td>\n",
       "      <td>189.710007</td>\n",
       "      <td>263.850006</td>\n",
       "      <td>265.320007</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.19</td>\n",
       "      <td>30603</td>\n",
       "      <td>1.19</td>\n",
       "      <td>53.509998</td>\n",
       "      <td>53.509998</td>\n",
       "      <td>53.509998</td>\n",
       "      <td>53.509998</td>\n",
       "      <td>0</td>\n",
       "      <td>53.509998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>191.130005</td>\n",
       "      <td>191.220001</td>\n",
       "      <td>189.449997</td>\n",
       "      <td>190.479996</td>\n",
       "      <td>29517500</td>\n",
       "      <td>190.479996</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>246.070007</td>\n",
       "      <td>...</td>\n",
       "      <td>1.15</td>\n",
       "      <td>9100</td>\n",
       "      <td>1.15</td>\n",
       "      <td>53.660000</td>\n",
       "      <td>53.660000</td>\n",
       "      <td>53.660000</td>\n",
       "      <td>53.660000</td>\n",
       "      <td>0</td>\n",
       "      <td>53.660000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>190.179993</td>\n",
       "      <td>190.690002</td>\n",
       "      <td>188.589996</td>\n",
       "      <td>190.649994</td>\n",
       "      <td>26359500</td>\n",
       "      <td>190.649994</td>\n",
       "      <td>246.500000</td>\n",
       "      <td>246.679993</td>\n",
       "      <td>231.130005</td>\n",
       "      <td>...</td>\n",
       "      <td>1.15</td>\n",
       "      <td>12270</td>\n",
       "      <td>1.15</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>0</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Index    QQQ.Open    QQQ.High     QQQ.Low   QQQ.Close  QQQ.Volume  \\\n",
       "3095  2019-04-22  186.570007  187.990005  186.429993  187.919998    17936000   \n",
       "3096  2019-04-23  188.399994  190.539993  188.130005  190.309998    33665600   \n",
       "3097  2019-04-24  190.470001  190.710007  189.649994  189.710007    24977100   \n",
       "3098  2019-04-25  191.130005  191.220001  189.449997  190.479996    29517500   \n",
       "3099  2019-04-26  190.179993  190.690002  188.589996  190.649994    26359500   \n",
       "\n",
       "      QQQ.Adjusted   TSLA.Open   TSLA.High    TSLA.Low       ...         \\\n",
       "3095    187.919998  269.000000  269.679993  262.480011       ...          \n",
       "3096    190.309998  260.149994  265.600006  255.750000       ...          \n",
       "3097    189.710007  263.850006  265.320007  258.000000       ...          \n",
       "3098    190.479996  255.000000  259.000000  246.070007       ...          \n",
       "3099    190.649994  246.500000  246.679993  231.130005       ...          \n",
       "\n",
       "      TNX.Close  TNX.Volume  TNX.Adjusted  RYSDX.Open  RYSDX.High  RYSDX.Low  \\\n",
       "3095       1.23       47944          1.23   52.619999   52.619999  52.619999   \n",
       "3096       1.19       16650          1.19   52.950001   52.950001  52.950001   \n",
       "3097       1.19       30603          1.19   53.509998   53.509998  53.509998   \n",
       "3098       1.15        9100          1.15   53.660000   53.660000  53.660000   \n",
       "3099       1.15       12270          1.15   53.490002   53.490002  53.490002   \n",
       "\n",
       "      RYSDX.Close  RYSDX.Volume  RYSDX.Adjusted  tick_pct_change  \n",
       "3095    52.619999             0       52.619999                0  \n",
       "3096    52.950001             0       52.950001                1  \n",
       "3097    53.509998             0       53.509998                1  \n",
       "3098    53.660000             0       53.660000                1  \n",
       "3099    53.490002             0       53.490002                0  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This works for next hypothesis\n",
    "theta = 0.01\n",
    "# pct_df = data.iloc[:,1:].pct_change(1) # all columns\n",
    "# data = pct_df[pct_df > theta].fillna(0).apply(lambda x: [1 if y > 0 else 0 for y in x])\n",
    "pct_df = data.iloc[:,ticker_lookup[CHOSENTICKER]].pct_change(1).fillna(0).apply(lambda y: 1 if y > 0 else 0) # 1 columns\n",
    "data[\"tick_pct_change\"] = pct_df\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_time = 90\n",
    "data = (data.iloc[:,1:] - data.iloc[:,1:].rolling(window_time).min()) / (data.iloc[:,1:].rolling(window_time).max() - data.iloc[:,1:].rolling(window_time).min())\n",
    "# data = data.iloc[:,1:]\n",
    "data.fillna(value=-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_mat = data.iloc[:,1:].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 5\n",
    "data = np.array((data_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 1.        ,  0.98492522,  0.98155738, ..., -1.        ,\n",
       "           0.80603509,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.93827159,  0.        ],\n",
       "         [ 0.97155416,  1.        ,  0.96027093, ..., -1.        ,\n",
       "           1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  0.97682692, ..., -1.        ,\n",
       "           0.96330276,  1.        ]],\n",
       " \n",
       "        [[ 0.80665276,  0.81175301,  0.79479444, ..., -1.        ,\n",
       "           0.12021878,  0.        ],\n",
       "         [ 0.76715122,  0.70318688,  0.67051427, ..., -1.        ,\n",
       "           0.19672157,  0.        ],\n",
       "         [ 0.66274069,  0.6529102 ,  0.62499969, ..., -1.        ,\n",
       "           0.16393458,  0.        ],\n",
       "         [ 0.61652274,  0.60163514,  0.57043043, ..., -1.        ,\n",
       "           0.14754108,  1.        ],\n",
       "         [ 0.5659675 ,  0.58665122,  0.56693812, ..., -1.        ,\n",
       "           0.12568309,  0.        ]],\n",
       " \n",
       "        [[ 0.93454012,  0.94084534,  0.90994654, ..., -1.        ,\n",
       "           0.95962315,  1.        ],\n",
       "         [ 0.83028209,  0.82426177,  0.82003099, ..., -1.        ,\n",
       "           1.        ,  0.        ],\n",
       "         [ 0.86432065,  0.9009738 ,  0.87949969, ..., -1.        ,\n",
       "           0.97435936,  1.        ],\n",
       "         [ 0.90284727,  0.89869354,  0.8243241 , ..., -1.        ,\n",
       "           0.93846154,  1.        ],\n",
       "         [ 0.97487405,  0.87435521,  0.89358138, ..., -1.        ,\n",
       "           0.90128192,  0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  0.99893638, ..., -1.        ,\n",
       "           0.0092308 ,  1.        ],\n",
       "         [ 0.99556038,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.04000001,  1.        ],\n",
       "         [ 1.        ,  0.99452366,  1.        , ..., -1.        ,\n",
       "           0.0676924 ,  0.        ]],\n",
       " \n",
       "        [[ 0.97584573,  0.96964887,  0.98032804, ..., -1.        ,\n",
       "           0.84710775,  0.        ],\n",
       "         [ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.74793413,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.75206637,  1.        ],\n",
       "         [ 0.99619029,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.84710775,  1.        ],\n",
       "         [ 1.        ,  0.94890547,  0.93474092, ..., -1.        ,\n",
       "           0.9338842 ,  1.        ]],\n",
       " \n",
       "        [[ 1.        ,  0.90432552,  0.97693377, ..., -1.        ,\n",
       "           0.30370318,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.20740682,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.20740682,  1.        ],\n",
       "         [ 0.97391318,  0.96237148,  0.98231119, ..., -1.        ,\n",
       "           0.12592609,  0.        ],\n",
       "         [ 0.99130435,  0.99201824,  0.97641544, ..., -1.        ,\n",
       "           0.13333352,  1.        ]]]), array([[0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]], dtype=float32), array([[[ 0.9769289 ,  0.97165532,  0.95657097, ..., -1.        ,\n",
       "           0.01119348,  0.        ],\n",
       "         [ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.99852696,  1.        ,  0.97049459, ..., -1.        ,\n",
       "           0.04204756,  1.        ],\n",
       "         [ 0.94364643,  0.93053553,  0.92072532, ..., -1.        ,\n",
       "           0.02010988,  0.        ],\n",
       "         [ 0.96464117,  0.94934844,  0.94560969, ..., -1.        ,\n",
       "           0.        ,  1.        ]],\n",
       " \n",
       "        [[ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.99852696,  1.        ,  0.97049459, ..., -1.        ,\n",
       "           0.04204756,  1.        ],\n",
       "         [ 0.94364643,  0.93053553,  0.92072532, ..., -1.        ,\n",
       "           0.02010988,  0.        ],\n",
       "         [ 0.96464117,  0.94934844,  0.94560969, ..., -1.        ,\n",
       "           0.        ,  1.        ],\n",
       "         [ 0.95506441,  0.91606342,  0.89441923, ..., -1.        ,\n",
       "           0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.99852696,  1.        ,  0.97049459, ..., -1.        ,\n",
       "           0.04204756,  1.        ],\n",
       "         [ 0.94364643,  0.93053553,  0.92072532, ..., -1.        ,\n",
       "           0.02010988,  0.        ],\n",
       "         [ 0.96464117,  0.94934844,  0.94560969, ..., -1.        ,\n",
       "           0.        ,  1.        ],\n",
       "         [ 0.95506441,  0.91606342,  0.89441923, ..., -1.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.88029463,  0.80531944,  0.77233454, ..., -1.        ,\n",
       "           0.09243687,  0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1.        ,  0.989423  ,  1.        , ..., -1.        ,\n",
       "           0.80000037,  0.        ],\n",
       "         [ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.86249911,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.84062442,  1.        ],\n",
       "         [ 0.99649562,  0.99281379,  1.        , ..., -1.        ,\n",
       "           1.        ,  0.        ],\n",
       "         [ 1.        ,  0.99605904,  1.        , ..., -1.        ,\n",
       "           0.94099319,  0.        ]],\n",
       " \n",
       "        [[ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.86249911,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.84062442,  1.        ],\n",
       "         [ 0.99649562,  0.99281379,  1.        , ..., -1.        ,\n",
       "           1.        ,  0.        ],\n",
       "         [ 1.        ,  0.99605904,  1.        , ..., -1.        ,\n",
       "           0.94099319,  0.        ],\n",
       "         [ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           1.        ,  1.        ]],\n",
       " \n",
       "        [[ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           0.84062442,  1.        ],\n",
       "         [ 0.99649562,  0.99281379,  1.        , ..., -1.        ,\n",
       "           1.        ,  0.        ],\n",
       "         [ 1.        ,  0.99605904,  1.        , ..., -1.        ,\n",
       "           0.94099319,  0.        ],\n",
       "         [ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "           1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  0.98718242, ..., -1.        ,\n",
       "           1.        ,  1.        ]]]), array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = seq_len + 1\n",
    "result = []\n",
    "for index in range(len(data) - sequence_length):\n",
    "    result.append(data[index: index + sequence_length])\n",
    "\n",
    "# if normalise_window:\n",
    "#     result = normalise_windows(result)\n",
    "\n",
    "result = np.array(result)\n",
    "\n",
    "row = round(0.9 * result.shape[0])\n",
    "train = result[:int(row), :]\n",
    "np.random.shuffle(train)\n",
    "x_train = train[:, :-1]\n",
    "y_train = train[:, -1]\n",
    "y_train = y_train[:,ticker_lookup[CHOSENTICKER]] # Extract QQQ_pct_change Only\n",
    "x_test = result[int(row):, :-1]\n",
    "y_test = result[int(row):, -1]\n",
    "y_test = y_test[:,ticker_lookup[CHOSENTICKER]] # Extract QQQ_pct_change Only\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# x_train = np.reshape(x_train, (1, x_train.shape[0], x_train.shape[1]))\n",
    "# x_test = np.reshape(x_test, (1, x_test.shape[0], x_test.shape[1]))  \n",
    "\n",
    "[x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  import sys\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(return_sequences=True, input_shape=(None, 198..., units=100)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compilation time :  0.03120279312133789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=2)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "LAYERS = 100\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(\n",
    "    input_dim=data.shape[1],\n",
    "    output_dim=LAYERS,\n",
    "    return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(\n",
    "    LAYERS,\n",
    "    return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(\n",
    "    output_dim=2))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "start = time.time()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "print('compilation time : ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "MODELNAME = 'multiplemodeltest'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=100, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('./forecast/models/'+MODELNAME+'_best.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=20, verbose=1, epsilon=1e-4, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1949 samples, validate on 836 samples\n",
      "Epoch 1/50\n",
      "1949/1949 [==============================] - 4s 2ms/step - loss: 0.6293 - val_loss: 0.4880\n",
      "Epoch 2/50\n",
      "1949/1949 [==============================] - 0s 225us/step - loss: 0.4787 - val_loss: 0.4570\n",
      "Epoch 3/50\n",
      "1949/1949 [==============================] - 0s 216us/step - loss: 0.4599 - val_loss: 0.4415\n",
      "Epoch 4/50\n",
      "1949/1949 [==============================] - 0s 217us/step - loss: 0.4436 - val_loss: 0.4294\n",
      "Epoch 5/50\n",
      "1949/1949 [==============================] - 0s 214us/step - loss: 0.4357 - val_loss: 0.4251\n",
      "Epoch 6/50\n",
      "1949/1949 [==============================] - 0s 219us/step - loss: 0.4301 - val_loss: 0.4174\n",
      "Epoch 7/50\n",
      "1949/1949 [==============================] - 0s 229us/step - loss: 0.4224 - val_loss: 0.4076\n",
      "Epoch 8/50\n",
      "1949/1949 [==============================] - 0s 240us/step - loss: 0.4093 - val_loss: 0.3959\n",
      "Epoch 9/50\n",
      "1949/1949 [==============================] - 1s 258us/step - loss: 0.3975 - val_loss: 0.3796\n",
      "Epoch 10/50\n",
      "1949/1949 [==============================] - 0s 252us/step - loss: 0.3848 - val_loss: 0.3627\n",
      "Epoch 11/50\n",
      "1949/1949 [==============================] - 1s 257us/step - loss: 0.3716 - val_loss: 0.3507\n",
      "Epoch 12/50\n",
      "1949/1949 [==============================] - 0s 243us/step - loss: 0.3601 - val_loss: 0.3428\n",
      "Epoch 13/50\n",
      "1949/1949 [==============================] - 0s 250us/step - loss: 0.3539 - val_loss: 0.3370\n",
      "Epoch 14/50\n",
      "1949/1949 [==============================] - 0s 242us/step - loss: 0.3442 - val_loss: 0.3303\n",
      "Epoch 15/50\n",
      "1949/1949 [==============================] - 0s 254us/step - loss: 0.3418 - val_loss: 0.3354\n",
      "Epoch 16/50\n",
      "1949/1949 [==============================] - 0s 235us/step - loss: 0.3380 - val_loss: 0.3198\n",
      "Epoch 17/50\n",
      "1949/1949 [==============================] - 0s 232us/step - loss: 0.3296 - val_loss: 0.3175\n",
      "Epoch 18/50\n",
      "1949/1949 [==============================] - 0s 234us/step - loss: 0.3259 - val_loss: 0.3147\n",
      "Epoch 19/50\n",
      "1949/1949 [==============================] - 0s 234us/step - loss: 0.3223 - val_loss: 0.3098\n",
      "Epoch 20/50\n",
      "1949/1949 [==============================] - 0s 236us/step - loss: 0.3210 - val_loss: 0.3244\n",
      "Epoch 21/50\n",
      "1949/1949 [==============================] - 0s 237us/step - loss: 0.3222 - val_loss: 0.3078\n",
      "Epoch 22/50\n",
      "1949/1949 [==============================] - 0s 235us/step - loss: 0.3170 - val_loss: 0.3051\n",
      "Epoch 23/50\n",
      "1949/1949 [==============================] - 0s 240us/step - loss: 0.3081 - val_loss: 0.3073\n",
      "Epoch 24/50\n",
      "1949/1949 [==============================] - 0s 237us/step - loss: 0.3136 - val_loss: 0.2999\n",
      "Epoch 25/50\n",
      "1949/1949 [==============================] - 1s 286us/step - loss: 0.3075 - val_loss: 0.3079\n",
      "Epoch 26/50\n",
      "1949/1949 [==============================] - 1s 289us/step - loss: 0.3045 - val_loss: 0.3030\n",
      "Epoch 27/50\n",
      "1949/1949 [==============================] - 0s 254us/step - loss: 0.2991 - val_loss: 0.2980\n",
      "Epoch 28/50\n",
      "1949/1949 [==============================] - 1s 264us/step - loss: 0.2934 - val_loss: 0.2949\n",
      "Epoch 29/50\n",
      "1949/1949 [==============================] - 1s 261us/step - loss: 0.2909 - val_loss: 0.2925\n",
      "Epoch 30/50\n",
      "1949/1949 [==============================] - 1s 276us/step - loss: 0.2888 - val_loss: 0.2922\n",
      "Epoch 31/50\n",
      "1949/1949 [==============================] - 1s 258us/step - loss: 0.2850 - val_loss: 0.2965\n",
      "Epoch 32/50\n",
      "1949/1949 [==============================] - 1s 264us/step - loss: 0.2888 - val_loss: 0.2980\n",
      "Epoch 33/50\n",
      "1949/1949 [==============================] - 1s 261us/step - loss: 0.2823 - val_loss: 0.3044\n",
      "Epoch 34/50\n",
      "1949/1949 [==============================] - 1s 264us/step - loss: 0.2921 - val_loss: 0.2997\n",
      "Epoch 35/50\n",
      "1949/1949 [==============================] - 0s 238us/step - loss: 0.2914 - val_loss: 0.2877\n",
      "Epoch 36/50\n",
      "1949/1949 [==============================] - 0s 231us/step - loss: 0.2793 - val_loss: 0.2874\n",
      "Epoch 37/50\n",
      "1949/1949 [==============================] - 0s 234us/step - loss: 0.2773 - val_loss: 0.2851\n",
      "Epoch 38/50\n",
      "1949/1949 [==============================] - 1s 276us/step - loss: 0.2694 - val_loss: 0.2808\n",
      "Epoch 39/50\n",
      "1949/1949 [==============================] - 0s 249us/step - loss: 0.2679 - val_loss: 0.2816\n",
      "Epoch 40/50\n",
      "1949/1949 [==============================] - 1s 259us/step - loss: 0.2641 - val_loss: 0.2798\n",
      "Epoch 41/50\n",
      "1949/1949 [==============================] - 0s 243us/step - loss: 0.2586 - val_loss: 0.2785\n",
      "Epoch 42/50\n",
      "1949/1949 [==============================] - 1s 309us/step - loss: 0.2616 - val_loss: 0.2775\n",
      "Epoch 43/50\n",
      "1949/1949 [==============================] - 1s 281us/step - loss: 0.2532 - val_loss: 0.2783\n",
      "Epoch 44/50\n",
      "1949/1949 [==============================] - 1s 263us/step - loss: 0.2570 - val_loss: 0.2951\n",
      "Epoch 45/50\n",
      "1949/1949 [==============================] - 1s 259us/step - loss: 0.2569 - val_loss: 0.2719\n",
      "Epoch 46/50\n",
      "1949/1949 [==============================] - 1s 274us/step - loss: 0.2518 - val_loss: 0.2745\n",
      "Epoch 47/50\n",
      "1949/1949 [==============================] - 0s 238us/step - loss: 0.2476 - val_loss: 0.2742\n",
      "Epoch 48/50\n",
      "1949/1949 [==============================] - 0s 249us/step - loss: 0.2541 - val_loss: 0.2805\n",
      "Epoch 49/50\n",
      "1949/1949 [==============================] - 0s 235us/step - loss: 0.2499 - val_loss: 0.2814\n",
      "Epoch 50/50\n",
      "1949/1949 [==============================] - 0s 235us/step - loss: 0.2509 - val_loss: 0.2703\n"
     ]
    }
   ],
   "source": [
    "VALIDATIONSIZE = 0.3\n",
    "EPOCHS = 50\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    nb_epoch=EPOCHS,\n",
    "    validation_split=VALIDATIONSIZE,\n",
    "    callbacks = [reduce_lr_loss, earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42479438, 0.5851572 ],\n",
       "       [0.40913737, 0.60308576],\n",
       "       [0.40641212, 0.606553  ],\n",
       "       [0.4096928 , 0.60166234],\n",
       "       [0.4305365 , 0.57708883]], dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 refers to days of data. 5 days worth. each 1 row has 36 features\n",
    "model.predict(np.reshape(data[-5:], (5, 1, data.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([k[1]/k[0] if k[1]/k[0] > 1 else 0 for k in model.predict(np.reshape(data[-5:], (5, 1, data.shape[1])))])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
