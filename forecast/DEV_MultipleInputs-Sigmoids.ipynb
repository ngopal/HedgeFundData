{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.callbacks import *\n",
    "from keras.models import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>QQQ.Open</th>\n",
       "      <th>QQQ.High</th>\n",
       "      <th>QQQ.Low</th>\n",
       "      <th>QQQ.Close</th>\n",
       "      <th>QQQ.Volume</th>\n",
       "      <th>QQQ.Adjusted</th>\n",
       "      <th>TSLA.Open</th>\n",
       "      <th>TSLA.High</th>\n",
       "      <th>TSLA.Low</th>\n",
       "      <th>...</th>\n",
       "      <th>TNX.Low</th>\n",
       "      <th>TNX.Close</th>\n",
       "      <th>TNX.Volume</th>\n",
       "      <th>TNX.Adjusted</th>\n",
       "      <th>RYSDX.Open</th>\n",
       "      <th>RYSDX.High</th>\n",
       "      <th>RYSDX.Low</th>\n",
       "      <th>RYSDX.Close</th>\n",
       "      <th>RYSDX.Volume</th>\n",
       "      <th>RYSDX.Adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>186.570007</td>\n",
       "      <td>187.990005</td>\n",
       "      <td>186.429993</td>\n",
       "      <td>187.919998</td>\n",
       "      <td>17936000</td>\n",
       "      <td>187.919998</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>269.679993</td>\n",
       "      <td>262.480011</td>\n",
       "      <td>...</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.23</td>\n",
       "      <td>47944</td>\n",
       "      <td>1.23</td>\n",
       "      <td>52.619999</td>\n",
       "      <td>52.619999</td>\n",
       "      <td>52.619999</td>\n",
       "      <td>52.619999</td>\n",
       "      <td>0</td>\n",
       "      <td>52.619999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>2019-04-23</td>\n",
       "      <td>188.399994</td>\n",
       "      <td>190.539993</td>\n",
       "      <td>188.130005</td>\n",
       "      <td>190.309998</td>\n",
       "      <td>33665600</td>\n",
       "      <td>190.309998</td>\n",
       "      <td>260.149994</td>\n",
       "      <td>265.600006</td>\n",
       "      <td>255.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.19</td>\n",
       "      <td>16650</td>\n",
       "      <td>1.19</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>0</td>\n",
       "      <td>52.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>190.470001</td>\n",
       "      <td>190.710007</td>\n",
       "      <td>189.649994</td>\n",
       "      <td>189.710007</td>\n",
       "      <td>24977100</td>\n",
       "      <td>189.710007</td>\n",
       "      <td>263.850006</td>\n",
       "      <td>265.320007</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.19</td>\n",
       "      <td>30603</td>\n",
       "      <td>1.19</td>\n",
       "      <td>53.509998</td>\n",
       "      <td>53.509998</td>\n",
       "      <td>53.509998</td>\n",
       "      <td>53.509998</td>\n",
       "      <td>0</td>\n",
       "      <td>53.509998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>191.130005</td>\n",
       "      <td>191.220001</td>\n",
       "      <td>189.449997</td>\n",
       "      <td>190.479996</td>\n",
       "      <td>29517500</td>\n",
       "      <td>190.479996</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>246.070007</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.15</td>\n",
       "      <td>9100</td>\n",
       "      <td>1.15</td>\n",
       "      <td>53.660000</td>\n",
       "      <td>53.660000</td>\n",
       "      <td>53.660000</td>\n",
       "      <td>53.660000</td>\n",
       "      <td>0</td>\n",
       "      <td>53.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>190.179993</td>\n",
       "      <td>190.690002</td>\n",
       "      <td>188.589996</td>\n",
       "      <td>190.649994</td>\n",
       "      <td>26359500</td>\n",
       "      <td>190.649994</td>\n",
       "      <td>246.500000</td>\n",
       "      <td>246.679993</td>\n",
       "      <td>231.130005</td>\n",
       "      <td>...</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.15</td>\n",
       "      <td>12270</td>\n",
       "      <td>1.15</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>53.490002</td>\n",
       "      <td>0</td>\n",
       "      <td>53.490002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Index    QQQ.Open    QQQ.High     QQQ.Low   QQQ.Close  QQQ.Volume  \\\n",
       "3095  2019-04-22  186.570007  187.990005  186.429993  187.919998    17936000   \n",
       "3096  2019-04-23  188.399994  190.539993  188.130005  190.309998    33665600   \n",
       "3097  2019-04-24  190.470001  190.710007  189.649994  189.710007    24977100   \n",
       "3098  2019-04-25  191.130005  191.220001  189.449997  190.479996    29517500   \n",
       "3099  2019-04-26  190.179993  190.690002  188.589996  190.649994    26359500   \n",
       "\n",
       "      QQQ.Adjusted   TSLA.Open   TSLA.High    TSLA.Low       ...        \\\n",
       "3095    187.919998  269.000000  269.679993  262.480011       ...         \n",
       "3096    190.309998  260.149994  265.600006  255.750000       ...         \n",
       "3097    189.710007  263.850006  265.320007  258.000000       ...         \n",
       "3098    190.479996  255.000000  259.000000  246.070007       ...         \n",
       "3099    190.649994  246.500000  246.679993  231.130005       ...         \n",
       "\n",
       "      TNX.Low  TNX.Close  TNX.Volume  TNX.Adjusted  RYSDX.Open  RYSDX.High  \\\n",
       "3095     1.14       1.23       47944          1.23   52.619999   52.619999   \n",
       "3096     1.19       1.19       16650          1.19   52.950001   52.950001   \n",
       "3097     1.13       1.19       30603          1.19   53.509998   53.509998   \n",
       "3098     1.12       1.15        9100          1.15   53.660000   53.660000   \n",
       "3099     1.13       1.15       12270          1.15   53.490002   53.490002   \n",
       "\n",
       "      RYSDX.Low  RYSDX.Close  RYSDX.Volume  RYSDX.Adjusted  \n",
       "3095  52.619999    52.619999             0       52.619999  \n",
       "3096  52.950001    52.950001             0       52.950001  \n",
       "3097  53.509998    53.509998             0       53.509998  \n",
       "3098  53.660000    53.660000             0       53.660000  \n",
       "3099  53.490002    53.490002             0       53.490002  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/files/multiple_concatenated_tickers.csv')\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAPL': 25,\n",
       " 'AMD': 67,\n",
       " 'AMZN': 37,\n",
       " 'DATA': 61,\n",
       " 'DIS': 145,\n",
       " 'DUK': 157,\n",
       " 'FB': 43,\n",
       " 'GLD': 175,\n",
       " 'HD': 151,\n",
       " 'INTC': 19,\n",
       " 'JNJ': 103,\n",
       " 'JWN': 91,\n",
       " 'KO': 109,\n",
       " 'MSFT': 13,\n",
       " 'NFLX': 31,\n",
       " 'NVDA': 127,\n",
       " 'PANW': 121,\n",
       " 'PG': 97,\n",
       " 'QQQ': 1,\n",
       " 'RHT': 133,\n",
       " 'RYSDX': 193,\n",
       " 'SBUX': 73,\n",
       " 'SLV': 181,\n",
       " 'SPOT': 163,\n",
       " 'SQ': 49,\n",
       " 'TGT': 85,\n",
       " 'TNX': 187,\n",
       " 'TSLA': 7,\n",
       " 'TWTR': 55,\n",
       " 'USO': 139,\n",
       " 'VRSN': 115,\n",
       " 'WDC': 169,\n",
       " 'WMT': 79}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_lookup = dict([(i[1].split('.')[0], int(i[0])) for i in enumerate(list(data.columns)) if 'Open' in i[1]])\n",
    "ticker_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHOSENTICKER = 'QQQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works for next hypothesis\n",
    "theta = 0.01\n",
    "# pct_df = data.iloc[:,1:].pct_change(1) # all columns\n",
    "# data = pct_df[pct_df > theta].fillna(0).apply(lambda x: [1 if y > 0 else 0 for y in x])\n",
    "pct_df = data.iloc[:,ticker_lookup[CHOSENTICKER]].pct_change(1).apply(lambda y: 1 if y > 0 else 0) # 1 columns\n",
    "# data[\"tick_pct_change\"] = pct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3095    0\n",
       "3096    1\n",
       "3097    1\n",
       "3098    1\n",
       "3099    0\n",
       "Name: QQQ.Open, dtype: int64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(data.iloc[:,1:])\n",
    "data_mat = scaler.transform(data.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_time = 30\n",
    "# data = (data.iloc[:,1:] - data.iloc[:,1:].rolling(window_time).min()) / (data.iloc[:,1:].rolling(window_time).max() - data.iloc[:,1:].rolling(window_time).min())\n",
    "# # data = data.iloc[:,1:]\n",
    "# data.fillna(value=-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_mat = data.iloc[:,1:].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 5\n",
    "data = np.array((data_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[[0.10568071, 0.10562782, 0.1061361 , ..., 0.80508467,\n",
       "          0.        , 0.74518362],\n",
       "         [0.10471172, 0.10653944, 0.10996357, ..., 0.81840194,\n",
       "          0.        , 0.76259358],\n",
       "         [0.10864826, 0.10495929, 0.11196842, ..., 0.8323245 ,\n",
       "          0.        , 0.78079487],\n",
       "         [0.10828487, 0.10599246, 0.11294047, ..., 0.82869254,\n",
       "          0.        , 0.77604663],\n",
       "         [0.10901161, 0.10702565, 0.11287972, ..., 0.83353512,\n",
       "          0.        , 0.78237736],\n",
       "         [0.10870881, 0.10927434, 0.11403403, ..., 0.84866829,\n",
       "          0.        , 0.80216132]],\n",
       " \n",
       "        [[0.10471172, 0.10653944, 0.10996357, ..., 0.81840194,\n",
       "          0.        , 0.76259358],\n",
       "         [0.10864826, 0.10495929, 0.11196842, ..., 0.8323245 ,\n",
       "          0.        , 0.78079487],\n",
       "         [0.10828487, 0.10599246, 0.11294047, ..., 0.82869254,\n",
       "          0.        , 0.77604663],\n",
       "         [0.10901161, 0.10702565, 0.11287972, ..., 0.83353512,\n",
       "          0.        , 0.78237736],\n",
       "         [0.10870881, 0.10927434, 0.11403403, ..., 0.84866829,\n",
       "          0.        , 0.80216132],\n",
       "         [0.11325096, 0.11279933, 0.11907657, ..., 0.85351084,\n",
       "          0.        , 0.80849206]],\n",
       " \n",
       "        [[0.10864826, 0.10495929, 0.11196842, ..., 0.8323245 ,\n",
       "          0.        , 0.78079487],\n",
       "         [0.10828487, 0.10599246, 0.11294047, ..., 0.82869254,\n",
       "          0.        , 0.77604663],\n",
       "         [0.10901161, 0.10702565, 0.11287972, ..., 0.83353512,\n",
       "          0.        , 0.78237736],\n",
       "         [0.10870881, 0.10927434, 0.11403403, ..., 0.84866829,\n",
       "          0.        , 0.80216132],\n",
       "         [0.11325096, 0.11279933, 0.11907657, ..., 0.85351084,\n",
       "          0.        , 0.80849206],\n",
       "         [0.11512839, 0.11346784, 0.12102067, ..., 0.84140434,\n",
       "          0.        , 0.79266513]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.84950336, 0.85960857, 0.85686514, ..., 0.13155772,\n",
       "          0.        , 0.28667408],\n",
       "         [0.86379599, 0.86896805, 0.87187122, ..., 0.12651333,\n",
       "          0.        , 0.27765804],\n",
       "         [0.8712451 , 0.87249304, 0.86506687, ..., 0.109766  ,\n",
       "          0.        , 0.24772488],\n",
       "         [0.86942831, 0.86878573, 0.86731472, ..., 0.11097659,\n",
       "          0.        , 0.24988862],\n",
       "         [0.86773249, 0.87680805, 0.87430141, ..., 0.10754644,\n",
       "          0.        , 0.24375778],\n",
       "         [0.87548451, 0.87656499, 0.87904016, ..., 0.11218728,\n",
       "          0.        , 0.25205254]],\n",
       " \n",
       "        [[0.86379599, 0.86896805, 0.87187122, ..., 0.12651333,\n",
       "          0.        , 0.27765804],\n",
       "         [0.8712451 , 0.87249304, 0.86506687, ..., 0.109766  ,\n",
       "          0.        , 0.24772488],\n",
       "         [0.86942831, 0.86878573, 0.86731472, ..., 0.11097659,\n",
       "          0.        , 0.24988862],\n",
       "         [0.86773249, 0.87680805, 0.87430141, ..., 0.10754644,\n",
       "          0.        , 0.24375778],\n",
       "         [0.87548451, 0.87656499, 0.87904016, ..., 0.11218728,\n",
       "          0.        , 0.25205254],\n",
       "         [0.86325096, 0.8675094 , 0.86737553, ..., 0.109766  ,\n",
       "          0.        , 0.24772488]],\n",
       " \n",
       "        [[0.8712451 , 0.87249304, 0.86506687, ..., 0.109766  ,\n",
       "          0.        , 0.24772488],\n",
       "         [0.86942831, 0.86878573, 0.86731472, ..., 0.11097659,\n",
       "          0.        , 0.24988862],\n",
       "         [0.86773249, 0.87680805, 0.87430141, ..., 0.10754644,\n",
       "          0.        , 0.24375778],\n",
       "         [0.87548451, 0.87656499, 0.87904016, ..., 0.11218728,\n",
       "          0.        , 0.25205254],\n",
       "         [0.86325096, 0.8675094 , 0.86737553, ..., 0.109766  ,\n",
       "          0.        , 0.24772488],\n",
       "         [0.86991273, 0.87097365, 0.87053464, ..., 0.10714289,\n",
       "          0.        , 0.2430365 ]]]), array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32), array([[[0.86942831, 0.86878573, 0.86731472, ..., 0.11097659,\n",
       "          0.        , 0.24988862],\n",
       "         [0.86773249, 0.87680805, 0.87430141, ..., 0.10754644,\n",
       "          0.        , 0.24375778],\n",
       "         [0.87548451, 0.87656499, 0.87904016, ..., 0.11218728,\n",
       "          0.        , 0.25205254],\n",
       "         [0.86325096, 0.8675094 , 0.86737553, ..., 0.109766  ,\n",
       "          0.        , 0.24772488],\n",
       "         [0.86991273, 0.87097365, 0.87053464, ..., 0.10714289,\n",
       "          0.        , 0.2430365 ],\n",
       "         [0.86052569, 0.86939343, 0.86494534, ..., 0.09786123,\n",
       "          0.        , 0.22644703]],\n",
       " \n",
       "        [[0.86773249, 0.87680805, 0.87430141, ..., 0.10754644,\n",
       "          0.        , 0.24375778],\n",
       "         [0.87548451, 0.87656499, 0.87904016, ..., 0.11218728,\n",
       "          0.        , 0.25205254],\n",
       "         [0.86325096, 0.8675094 , 0.86737553, ..., 0.109766  ,\n",
       "          0.        , 0.24772488],\n",
       "         [0.86991273, 0.87097365, 0.87053464, ..., 0.10714289,\n",
       "          0.        , 0.2430365 ],\n",
       "         [0.86052569, 0.86939343, 0.86494534, ..., 0.09786123,\n",
       "          0.        , 0.22644703],\n",
       "         [0.85568071, 0.85705601, 0.84702312, ..., 0.10895887,\n",
       "          0.        , 0.24628227]],\n",
       " \n",
       "        [[0.87548451, 0.87656499, 0.87904016, ..., 0.11218728,\n",
       "          0.        , 0.25205254],\n",
       "         [0.86325096, 0.8675094 , 0.86737553, ..., 0.109766  ,\n",
       "          0.        , 0.24772488],\n",
       "         [0.86991273, 0.87097365, 0.87053464, ..., 0.10714289,\n",
       "          0.        , 0.2430365 ],\n",
       "         [0.86052569, 0.86939343, 0.86494534, ..., 0.09786123,\n",
       "          0.        , 0.22644703],\n",
       "         [0.85568071, 0.85705601, 0.84702312, ..., 0.10895887,\n",
       "          0.        , 0.24628227],\n",
       "         [0.830063  , 0.84520481, 0.8077157 , ..., 0.11723167,\n",
       "          0.        , 0.26106857]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.96796264, 0.96870066, 0.96944107, ..., 0.30468124,\n",
       "          0.        , 0.59610453],\n",
       "         [0.97220196, 0.97380578, 0.97739975, ..., 0.30871667,\n",
       "          0.        , 0.60331722],\n",
       "         [0.97953001, 0.98000481, 0.9814703 , ..., 0.30730427,\n",
       "          0.        , 0.60079276],\n",
       "         [0.97777375, 0.97915396, 0.97958687, ..., 0.31799841,\n",
       "          0.        , 0.61990683],\n",
       "         [0.97238373, 0.98036954, 0.98043742, ..., 0.31416464,\n",
       "          0.        , 0.61305457],\n",
       "         [0.9834665 , 0.99586722, 0.99076556, ..., 0.32082327,\n",
       "          0.        , 0.62495581]],\n",
       " \n",
       "        [[0.97220196, 0.97380578, 0.97739975, ..., 0.30871667,\n",
       "          0.        , 0.60331722],\n",
       "         [0.97953001, 0.98000481, 0.9814703 , ..., 0.30730427,\n",
       "          0.        , 0.60079276],\n",
       "         [0.97777375, 0.97915396, 0.97958687, ..., 0.31799841,\n",
       "          0.        , 0.61990683],\n",
       "         [0.97238373, 0.98036954, 0.98043742, ..., 0.31416464,\n",
       "          0.        , 0.61305457],\n",
       "         [0.9834665 , 0.99586722, 0.99076556, ..., 0.32082327,\n",
       "          0.        , 0.62495581],\n",
       "         [0.99600288, 0.99690049, 1.        , ..., 0.33212265,\n",
       "          0.        , 0.64515163]],\n",
       " \n",
       "        [[0.97953001, 0.98000481, 0.9814703 , ..., 0.30730427,\n",
       "          0.        , 0.60079276],\n",
       "         [0.97777375, 0.97915396, 0.97958687, ..., 0.31799841,\n",
       "          0.        , 0.61990683],\n",
       "         [0.97238373, 0.98036954, 0.98043742, ..., 0.31416464,\n",
       "          0.        , 0.61305457],\n",
       "         [0.9834665 , 0.99586722, 0.99076556, ..., 0.32082327,\n",
       "          0.        , 0.62495581],\n",
       "         [0.99600288, 0.99690049, 1.        , ..., 0.33212265,\n",
       "          0.        , 0.64515163],\n",
       "         [1.        , 1.        , 0.99878495, ..., 0.33514932,\n",
       "          0.        , 0.65056132]]]), array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = seq_len + 1\n",
    "result = []\n",
    "for index in range(len(data) - sequence_length):\n",
    "    result.append(data[index: index + sequence_length])\n",
    "\n",
    "# if normalise_window:\n",
    "#     result = normalise_windows(result)\n",
    "\n",
    "result = np.array(result)\n",
    "\n",
    "row = round(0.9 * result.shape[0])\n",
    "train = result[:int(row), :]\n",
    "# np.random.shuffle(train)\n",
    "# x_train = train[:, :-1]\n",
    "# y_train = train[:, -1]\n",
    "# y_train = y_train[:,ticker_lookup[CHOSENTICKER]] # Extract QQQ_pct_change Only\n",
    "# x_test = result[int(row):, :-1]\n",
    "# y_test = result[int(row):, -1]\n",
    "# y_test = y_test[:,ticker_lookup[CHOSENTICKER]] # Extract QQQ_pct_change Only\n",
    "\n",
    "x_train = result[:int(row), :]\n",
    "y_train = pct_df.as_matrix()[:int(row)]\n",
    "x_test = result[int(row):, :]\n",
    "y_test = pct_df.as_matrix()[int(row):]\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# x_train = np.reshape(x_train, (1, x_train.shape[0], x_train.shape[1]))\n",
    "# x_test = np.reshape(x_test, (1, x_test.shape[0], x_test.shape[1]))  \n",
    "\n",
    "[x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  import sys\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(return_sequences=True, input_shape=(None, 198..., units=100)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compilation time :  0.0766611099243164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=2)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "LAYERS = 100\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(\n",
    "    input_dim=data.shape[1],\n",
    "    output_dim=LAYERS,\n",
    "    return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(\n",
    "    LAYERS,\n",
    "    return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(\n",
    "    output_dim=2))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "start = time.time()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "print('compilation time : ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "MODELNAME = 'multiplemodeltest'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=100, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('./forecast/models/'+MODELNAME+'_best.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=20, verbose=1, epsilon=1e-4, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1949 samples, validate on 836 samples\n",
      "Epoch 1/50\n",
      "1949/1949 [==============================] - 10s 5ms/step - loss: 0.6871 - val_loss: 0.6870\n",
      "Epoch 2/50\n",
      "1949/1949 [==============================] - 1s 340us/step - loss: 0.6872 - val_loss: 0.6815\n",
      "Epoch 3/50\n",
      "1949/1949 [==============================] - 1s 428us/step - loss: 0.6853 - val_loss: 0.6794\n",
      "Epoch 4/50\n",
      "1949/1949 [==============================] - 1s 417us/step - loss: 0.6844 - val_loss: 0.6874\n",
      "Epoch 5/50\n",
      "1949/1949 [==============================] - 1s 431us/step - loss: 0.6843 - val_loss: 0.6890\n",
      "Epoch 6/50\n",
      "1949/1949 [==============================] - 1s 425us/step - loss: 0.6834 - val_loss: 0.6855\n",
      "Epoch 7/50\n",
      "1949/1949 [==============================] - 1s 422us/step - loss: 0.6826 - val_loss: 0.6889\n",
      "Epoch 8/50\n",
      "1949/1949 [==============================] - 1s 427us/step - loss: 0.6811 - val_loss: 0.6905\n",
      "Epoch 9/50\n",
      "1949/1949 [==============================] - 1s 419us/step - loss: 0.6804 - val_loss: 0.7037\n",
      "Epoch 10/50\n",
      "1949/1949 [==============================] - 1s 413us/step - loss: 0.6795 - val_loss: 0.7040\n",
      "Epoch 11/50\n",
      "1949/1949 [==============================] - 1s 416us/step - loss: 0.6781 - val_loss: 0.6944\n",
      "Epoch 12/50\n",
      "1949/1949 [==============================] - 1s 428us/step - loss: 0.6778 - val_loss: 0.7085\n",
      "Epoch 13/50\n",
      "1949/1949 [==============================] - 1s 420us/step - loss: 0.6782 - val_loss: 0.7001\n",
      "Epoch 14/50\n",
      "1949/1949 [==============================] - 1s 424us/step - loss: 0.6756 - val_loss: 0.7155\n",
      "Epoch 15/50\n",
      "1949/1949 [==============================] - 1s 427us/step - loss: 0.6745 - val_loss: 0.7047\n",
      "Epoch 16/50\n",
      "1949/1949 [==============================] - 1s 420us/step - loss: 0.6750 - val_loss: 0.7542\n",
      "Epoch 17/50\n",
      "1949/1949 [==============================] - 1s 458us/step - loss: 0.6752 - val_loss: 0.7147\n",
      "Epoch 18/50\n",
      "1949/1949 [==============================] - 1s 442us/step - loss: 0.6741 - val_loss: 0.7006\n",
      "Epoch 19/50\n",
      "1949/1949 [==============================] - 1s 448us/step - loss: 0.6726 - val_loss: 0.7092\n",
      "Epoch 20/50\n",
      "1949/1949 [==============================] - 1s 389us/step - loss: 0.6740 - val_loss: 0.7199\n",
      "Epoch 21/50\n",
      "1949/1949 [==============================] - 1s 425us/step - loss: 0.6757 - val_loss: 0.7077\n",
      "Epoch 22/50\n",
      "1949/1949 [==============================] - 1s 419us/step - loss: 0.6737 - val_loss: 0.6914\n",
      "Epoch 23/50\n",
      "1949/1949 [==============================] - 1s 437us/step - loss: 0.6748 - val_loss: 0.7158\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 24/50\n",
      "1949/1949 [==============================] - 1s 333us/step - loss: 0.6708 - val_loss: 0.7100\n",
      "Epoch 25/50\n",
      "1949/1949 [==============================] - 1s 402us/step - loss: 0.6713 - val_loss: 0.6900\n",
      "Epoch 26/50\n",
      "1949/1949 [==============================] - 1s 399us/step - loss: 0.6694 - val_loss: 0.7100\n",
      "Epoch 27/50\n",
      "1949/1949 [==============================] - 1s 419us/step - loss: 0.6691 - val_loss: 0.7130\n",
      "Epoch 28/50\n",
      "1949/1949 [==============================] - 1s 421us/step - loss: 0.6707 - val_loss: 0.7001\n",
      "Epoch 29/50\n",
      "1949/1949 [==============================] - 1s 426us/step - loss: 0.6703 - val_loss: 0.7229\n",
      "Epoch 30/50\n",
      "1949/1949 [==============================] - 1s 415us/step - loss: 0.6691 - val_loss: 0.7080\n",
      "Epoch 31/50\n",
      "1949/1949 [==============================] - 1s 411us/step - loss: 0.6689 - val_loss: 0.7134\n",
      "Epoch 32/50\n",
      "1949/1949 [==============================] - 1s 433us/step - loss: 0.6680 - val_loss: 0.7099\n",
      "Epoch 33/50\n",
      "1949/1949 [==============================] - 1s 449us/step - loss: 0.6682 - val_loss: 0.7276\n",
      "Epoch 34/50\n",
      "1949/1949 [==============================] - 1s 411us/step - loss: 0.6687 - val_loss: 0.7275\n",
      "Epoch 35/50\n",
      "1949/1949 [==============================] - 1s 430us/step - loss: 0.6666 - val_loss: 0.7096\n",
      "Epoch 36/50\n",
      "1949/1949 [==============================] - 1s 433us/step - loss: 0.6679 - val_loss: 0.7152\n",
      "Epoch 37/50\n",
      "1949/1949 [==============================] - 1s 432us/step - loss: 0.6659 - val_loss: 0.7116\n",
      "Epoch 38/50\n",
      "1949/1949 [==============================] - 1s 457us/step - loss: 0.6685 - val_loss: 0.7179\n",
      "Epoch 39/50\n",
      "1949/1949 [==============================] - 1s 418us/step - loss: 0.6661 - val_loss: 0.7130\n",
      "Epoch 40/50\n",
      "1949/1949 [==============================] - 1s 430us/step - loss: 0.6671 - val_loss: 0.7058\n",
      "Epoch 41/50\n",
      "1949/1949 [==============================] - 1s 435us/step - loss: 0.6684 - val_loss: 0.7203\n",
      "Epoch 42/50\n",
      "1949/1949 [==============================] - 1s 427us/step - loss: 0.6701 - val_loss: 0.7131\n",
      "Epoch 43/50\n",
      "1949/1949 [==============================] - 1s 434us/step - loss: 0.6724 - val_loss: 0.6949\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 44/50\n",
      "1949/1949 [==============================] - 1s 429us/step - loss: 0.6647 - val_loss: 0.7148\n",
      "Epoch 45/50\n",
      "1949/1949 [==============================] - 1s 430us/step - loss: 0.6672 - val_loss: 0.7097\n",
      "Epoch 46/50\n",
      "1949/1949 [==============================] - 1s 434us/step - loss: 0.6661 - val_loss: 0.6926\n",
      "Epoch 47/50\n",
      "1949/1949 [==============================] - 1s 431us/step - loss: 0.6670 - val_loss: 0.7042\n",
      "Epoch 48/50\n",
      "1949/1949 [==============================] - 1s 422us/step - loss: 0.6637 - val_loss: 0.7151\n",
      "Epoch 49/50\n",
      "1949/1949 [==============================] - 1s 471us/step - loss: 0.6639 - val_loss: 0.7086\n",
      "Epoch 50/50\n",
      "1949/1949 [==============================] - 1s 421us/step - loss: 0.6641 - val_loss: 0.7005\n"
     ]
    }
   ],
   "source": [
    "VALIDATIONSIZE = 0.3\n",
    "EPOCHS = 50\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    nb_epoch=EPOCHS,\n",
    "    validation_split=VALIDATIONSIZE,\n",
    "    callbacks = [reduce_lr_loss, earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47872287, 0.51163995],\n",
       "       [0.47823688, 0.5122606 ],\n",
       "       [0.4774695 , 0.51286876],\n",
       "       [0.47879517, 0.5118078 ],\n",
       "       [0.48144108, 0.50956196]], dtype=float32)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 refers to days of data. 5 days worth. each 1 row has 36 features\n",
    "model.predict(np.reshape(data[-5:], (5, 1, data.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([k[1]/k[0] if k[1]/k[0] > 1 else 0 for k in model.predict(np.reshape(data[-5:], (5, 1, data.shape[1])))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([k[1] for k in model.predict(np.reshape(data[-5:], (5, 1, data.shape[1])))])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
